/home/nyarava/miniconda3/envs/yolo/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
{'GPU': None, 'model_name': 'swin_base', 'init': 'ark', 'pretrained_weights': '/home/nyarava/ARK/Ark/ark6_teacher_ep200_swinb_projector1376_mlp.pth.tar', 'num_class': 14, 'data_set': 'CheXpert', 'normalization': 'imagenet', 'img_size': 224, 'img_depth': 3, 'data_dir': '/scratch/nyarava/hey.zip/chexpertchestxrays-u20210408/', 'train_list': '/scratch/nyarava/hey.zip/chexpertchestxrays-u20210408/CheXpert-v1.0/train.csv', 'val_list': '/scratch/nyarava/hey.zip/chexpertchestxrays-u20210408/CheXpert-v1.0/valid.csv', 'test_list': '/scratch/nyarava/hey.zip/chexpertchestxrays-u20210408/CheXpert-v1.0/test_labels.csv', 'mode': 'train', 'batch_size': 64, 'epochs': 40, 'exp_name': '', 'opt': 'sgd', 'opt_eps': 1e-08, 'opt_betas': None, 'clip_grad': None, 'momentum': 0.9, 'weight_decay': 0.0, 'sched': 'cosine', 'lr': 0.01, 'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, 'warmup_lr': 1e-06, 'min_lr': 1e-05, 'decay_epochs': 30, 'warmup_epochs': 0, 'cooldown_epochs': 10, 'decay_rate': 0.5, 'patience': 10, 'early_stop': True, 'num_trial': 1, 'start_index': 0, 'clean': False, 'resume': False, 'workers': 8, 'print_freq': 50, 'test_augment': True, 'anno_percent': 100, 'device': 'cuda', 'activate': 'Sigmoid', 'uncertain_label': 'LSR-Ones', 'unknown_label': 0}
start training....
run: 1
Creating model...
Creating model from pretrained weights: /home/nyarava/ARK/Ark/ark6_teacher_ep200_swinb_projector1376_mlp.pth.tar
Removing key head.weight from pretrained checkpoint
Removing key head.bias from pretrained checkpoint
Loaded with msg: _IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['projector.0.weight', 'projector.0.bias', 'projector.2.weight', 'projector.2.bias', 'omni_heads.0.weight', 'omni_heads.0.bias', 'omni_heads.1.weight', 'omni_heads.1.bias', 'omni_heads.2.weight', 'omni_heads.2.bias', 'omni_heads.3.weight', 'omni_heads.3.bias', 'omni_heads.4.weight', 'omni_heads.4.bias', 'omni_heads.5.weight', 'omni_heads.5.bias'])
SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): Sequential(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0-17): 18 x SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=14, bias=True)
)
Epoch: [0][   0/3491]	Time 22.507 (22.507)	Loss 7.2957e-01 (7.2957e-01)
Epoch: [0][  50/3491]	Time  0.483 ( 1.814)	Loss 3.5264e-01 (4.0136e-01)
Epoch: [0][ 100/3491]	Time  0.483 ( 1.659)	Loss 3.5286e-01 (3.7711e-01)
Epoch: [0][ 150/3491]	Time  0.483 ( 1.604)	Loss 3.3700e-01 (3.6670e-01)
Epoch: [0][ 200/3491]	Time  8.693 ( 1.624)	Loss 3.4048e-01 (3.6166e-01)
Epoch: [0][ 250/3491]	Time  0.483 ( 1.606)	Loss 3.4455e-01 (3.5824e-01)
Epoch: [0][ 300/3491]	Time  0.483 ( 1.593)	Loss 3.6635e-01 (3.5552e-01)
Epoch: [0][ 350/3491]	Time  0.483 ( 1.581)	Loss 3.4925e-01 (3.5386e-01)
Epoch: [0][ 400/3491]	Time  6.186 ( 1.584)	Loss 3.2170e-01 (3.5177e-01)
Epoch: [0][ 450/3491]	Time  0.483 ( 1.575)	Loss 3.7451e-01 (3.5092e-01)
Epoch: [0][ 500/3491]	Time  0.483 ( 1.570)	Loss 3.2719e-01 (3.5008e-01)
Epoch: [0][ 550/3491]	Time  0.483 ( 1.563)	Loss 3.3535e-01 (3.4933e-01)
Epoch: [0][ 600/3491]	Time  5.864 ( 1.563)	Loss 3.4177e-01 (3.4868e-01)
Epoch: [0][ 650/3491]	Time  0.483 ( 1.557)	Loss 3.3773e-01 (3.4800e-01)
Epoch: [0][ 700/3491]	Time  0.483 ( 1.552)	Loss 3.4130e-01 (3.4716e-01)
Epoch: [0][ 750/3491]	Time  0.483 ( 1.554)	Loss 3.3824e-01 (3.4661e-01)
Epoch: [0][ 800/3491]	Time  3.164 ( 1.553)	Loss 3.5421e-01 (3.4589e-01)
Epoch: [0][ 850/3491]	Time  0.483 ( 1.551)	Loss 3.4206e-01 (3.4540e-01)
Epoch: [0][ 900/3491]	Time  0.483 ( 1.553)	Loss 3.0303e-01 (3.4507e-01)
Epoch: [0][ 950/3491]	Time  0.483 ( 1.551)	Loss 3.1494e-01 (3.4470e-01)
Epoch: [0][1000/3491]	Time  7.823 ( 1.553)	Loss 2.9865e-01 (3.4411e-01)
Epoch: [0][1050/3491]	Time  0.483 ( 1.550)	Loss 3.2492e-01 (3.4362e-01)
Epoch: [0][1100/3491]	Time  0.483 ( 1.547)	Loss 3.0709e-01 (3.4343e-01)
Epoch: [0][1150/3491]	Time  0.483 ( 1.544)	Loss 3.2127e-01 (3.4315e-01)
Epoch: [0][1200/3491]	Time  4.119 ( 1.544)	Loss 3.1922e-01 (3.4289e-01)
Epoch: [0][1250/3491]	Time  0.483 ( 1.542)	Loss 3.3216e-01 (3.4256e-01)
Epoch: [0][1300/3491]	Time  0.483 ( 1.543)	Loss 3.1294e-01 (3.4234e-01)
Epoch: [0][1350/3491]	Time  0.482 ( 1.541)	Loss 2.9818e-01 (3.4220e-01)
Epoch: [0][1400/3491]	Time  4.109 ( 1.542)	Loss 3.2988e-01 (3.4202e-01)
Epoch: [0][1450/3491]	Time  0.483 ( 1.539)	Loss 3.3672e-01 (3.4190e-01)
Epoch: [0][1500/3491]	Time  0.483 ( 1.539)	Loss 3.5893e-01 (3.4175e-01)
Epoch: [0][1550/3491]	Time  0.483 ( 1.542)	Loss 3.4670e-01 (3.4150e-01)
Epoch: [0][1600/3491]	Time  1.765 ( 1.540)	Loss 3.5626e-01 (3.4144e-01)
Epoch: [0][1650/3491]	Time  0.483 ( 1.538)	Loss 3.3919e-01 (3.4129e-01)
Epoch: [0][1700/3491]	Time  0.483 ( 1.541)	Loss 3.4472e-01 (3.4103e-01)
Epoch: [0][1750/3491]	Time  0.484 ( 1.539)	Loss 3.4110e-01 (3.4099e-01)
Epoch: [0][1800/3491]	Time  0.484 ( 1.538)	Loss 3.2281e-01 (3.4083e-01)
Epoch: [0][1850/3491]	Time  0.483 ( 1.536)	Loss 3.1195e-01 (3.4065e-01)
Epoch: [0][1900/3491]	Time  0.483 ( 1.539)	Loss 3.2971e-01 (3.4042e-01)
Epoch: [0][1950/3491]	Time  0.484 ( 1.539)	Loss 3.3972e-01 (3.4035e-01)
Epoch: [0][2000/3491]	Time  0.483 ( 1.538)	Loss 3.4334e-01 (3.4029e-01)
Epoch: [0][2050/3491]	Time  0.483 ( 1.537)	Loss 3.4784e-01 (3.4016e-01)
Epoch: [0][2100/3491]	Time  0.483 ( 1.538)	Loss 3.5932e-01 (3.3997e-01)
Epoch: [0][2150/3491]	Time  0.484 ( 1.540)	Loss 3.4617e-01 (3.3984e-01)
Epoch: [0][2200/3491]	Time  0.483 ( 1.538)	Loss 3.3460e-01 (3.3977e-01)
Epoch: [0][2250/3491]	Time  0.483 ( 1.536)	Loss 3.3446e-01 (3.3974e-01)
Epoch: [0][2300/3491]	Time  0.483 ( 1.534)	Loss 3.0045e-01 (3.3957e-01)
Epoch: [0][2350/3491]	Time  0.483 ( 1.536)	Loss 3.3009e-01 (3.3945e-01)
Epoch: [0][2400/3491]	Time  0.483 ( 1.534)	Loss 3.3097e-01 (3.3932e-01)
Epoch: [0][2450/3491]	Time  0.483 ( 1.532)	Loss 3.4525e-01 (3.3920e-01)
Epoch: [0][2500/3491]	Time  0.483 ( 1.530)	Loss 3.2564e-01 (3.3912e-01)
Epoch: [0][2550/3491]	Time  0.483 ( 1.532)	Loss 3.2304e-01 (3.3900e-01)
Epoch: [0][2600/3491]	Time  0.483 ( 1.531)	Loss 3.2248e-01 (3.3896e-01)
Epoch: [0][2650/3491]	Time  0.483 ( 1.529)	Loss 3.4681e-01 (3.3890e-01)
Epoch: [0][2700/3491]	Time  0.483 ( 1.529)	Loss 3.4239e-01 (3.3890e-01)
Epoch: [0][2750/3491]	Time  0.483 ( 1.530)	Loss 3.1878e-01 (3.3886e-01)
Epoch: [0][2800/3491]	Time  0.483 ( 1.529)	Loss 3.0957e-01 (3.3881e-01)
Epoch: [0][2850/3491]	Time  0.483 ( 1.527)	Loss 3.2847e-01 (3.3874e-01)
Epoch: [0][2900/3491]	Time  0.483 ( 1.525)	Loss 3.1332e-01 (3.3867e-01)
Epoch: [0][2950/3491]	Time  0.483 ( 1.527)	Loss 3.7117e-01 (3.3861e-01)
Epoch: [0][3000/3491]	Time  0.483 ( 1.525)	Loss 3.1450e-01 (3.3854e-01)
Epoch: [0][3050/3491]	Time  0.483 ( 1.524)	Loss 3.7853e-01 (3.3843e-01)
Epoch: [0][3100/3491]	Time  0.483 ( 1.522)	Loss 3.2297e-01 (3.3835e-01)
Epoch: [0][3150/3491]	Time  0.483 ( 1.523)	Loss 3.2715e-01 (3.3822e-01)
Epoch: [0][3200/3491]	Time  0.483 ( 1.522)	Loss 3.6765e-01 (3.3815e-01)
Epoch: [0][3250/3491]	Time  0.483 ( 1.521)	Loss 3.2464e-01 (3.3810e-01)
Epoch: [0][3300/3491]	Time  0.483 ( 1.520)	Loss 3.6810e-01 (3.3806e-01)
Epoch: [0][3350/3491]	Time  0.483 ( 1.520)	Loss 3.1553e-01 (3.3801e-01)
Epoch: [0][3400/3491]	Time  0.483 ( 1.519)	Loss 3.4828e-01 (3.3796e-01)
Epoch: [0][3450/3491]	Time  0.483 ( 1.519)	Loss 3.0981e-01 (3.3784e-01)
Val: [0/4]	Time 11.575 (11.575)	Loss 2.7766e-01 (2.7766e-01)
Epoch 0000: val_loss improved from 1000000.00000 to 0.33646, saving model to ./Models/Classification/CheXpert/swin_base_ark/swin_base_ark_run_0
Epoch: [1][   0/3491]	Time 10.558 (10.558)	Loss 3.1748e-01 (3.1748e-01)
Epoch: [1][  50/3491]	Time  0.483 ( 1.478)	Loss 3.3503e-01 (3.3380e-01)
Epoch: [1][ 100/3491]	Time  0.483 ( 1.367)	Loss 3.2156e-01 (3.3474e-01)
Epoch: [1][ 150/3491]	Time  0.483 ( 1.346)	Loss 3.5093e-01 (3.3330e-01)
Epoch: [1][ 200/3491]	Time  7.337 ( 1.354)	Loss 3.2261e-01 (3.3267e-01)
Epoch: [1][ 250/3491]	Time  0.483 ( 1.344)	Loss 3.8411e-01 (3.3313e-01)
Epoch: [1][ 300/3491]	Time  0.483 ( 1.331)	Loss 3.4381e-01 (3.3298e-01)
Epoch: [1][ 350/3491]	Time  0.483 ( 1.326)	Loss 3.1444e-01 (3.3246e-01)
Epoch: [1][ 400/3491]	Time  7.083 ( 1.334)	Loss 3.4895e-01 (3.3244e-01)
Epoch: [1][ 450/3491]	Time  0.483 ( 1.332)	Loss 3.1733e-01 (3.3285e-01)
Epoch: [1][ 500/3491]	Time  0.483 ( 1.330)	Loss 3.3624e-01 (3.3287e-01)
Epoch: [1][ 550/3491]	Time  0.483 ( 1.331)	Loss 3.3137e-01 (3.3293e-01)
Epoch: [1][ 600/3491]	Time  6.488 ( 1.342)	Loss 3.6524e-01 (3.3331e-01)
Epoch: [1][ 650/3491]	Time  1.159 ( 1.345)	Loss 3.5431e-01 (3.3318e-01)
Epoch: [1][ 700/3491]	Time  0.483 ( 1.346)	Loss 3.3844e-01 (3.3300e-01)
Epoch: [1][ 750/3491]	Time  0.483 ( 1.346)	Loss 3.1987e-01 (3.3282e-01)
Epoch: [1][ 800/3491]	Time  7.056 ( 1.353)	Loss 3.5963e-01 (3.3257e-01)
Epoch: [1][ 850/3491]	Time  0.483 ( 1.353)	Loss 3.3319e-01 (3.3239e-01)
Epoch: [1][ 900/3491]	Time  0.483 ( 1.353)	Loss 3.3038e-01 (3.3254e-01)
Epoch: [1][ 950/3491]	Time  0.483 ( 1.355)	Loss 3.4246e-01 (3.3265e-01)
Epoch: [1][1000/3491]	Time  7.861 ( 1.364)	Loss 3.4380e-01 (3.3259e-01)
Epoch: [1][1050/3491]	Time  0.492 ( 1.364)	Loss 3.2741e-01 (3.3281e-01)
Epoch: [1][1100/3491]	Time  0.658 ( 1.366)	Loss 3.4036e-01 (3.3279e-01)
Epoch: [1][1150/3491]	Time  0.483 ( 1.368)	Loss 3.1370e-01 (3.3267e-01)
Epoch: [1][1200/3491]	Time  1.942 ( 1.371)	Loss 3.3577e-01 (3.3281e-01)
Epoch: [1][1250/3491]	Time  1.822 ( 1.377)	Loss 3.3927e-01 (3.3266e-01)
Epoch: [1][1300/3491]	Time  2.113 ( 1.380)	Loss 3.3163e-01 (3.3266e-01)
Epoch: [1][1350/3491]	Time  0.483 ( 1.382)	Loss 3.0862e-01 (3.3262e-01)
Epoch: [1][1400/3491]	Time  0.483 ( 1.384)	Loss 3.3040e-01 (3.3256e-01)
Epoch: [1][1450/3491]	Time  0.483 ( 1.392)	Loss 3.7078e-01 (3.3258e-01)
Epoch: [1][1500/3491]	Time  0.483 ( 1.393)	Loss 3.1111e-01 (3.3262e-01)
Epoch: [1][1550/3491]	Time  0.483 ( 1.395)	Loss 3.0616e-01 (3.3239e-01)
Epoch: [1][1600/3491]	Time  0.483 ( 1.396)	Loss 3.0264e-01 (3.3227e-01)
Epoch: [1][1650/3491]	Time  0.483 ( 1.404)	Loss 3.5655e-01 (3.3214e-01)
Epoch: [1][1700/3491]	Time  0.483 ( 1.406)	Loss 3.3850e-01 (3.3197e-01)
Epoch: [1][1750/3491]	Time  0.483 ( 1.407)	Loss 3.3162e-01 (3.3175e-01)
Epoch: [1][1800/3491]	Time  0.483 ( 1.411)	Loss 3.2882e-01 (3.3169e-01)
Epoch: [1][1850/3491]	Time  5.438 ( 1.420)	Loss 3.2648e-01 (3.3188e-01)
Epoch: [1][1900/3491]	Time  0.483 ( 1.422)	Loss 3.6307e-01 (3.3187e-01)
Epoch: [1][1950/3491]	Time  0.483 ( 1.425)	Loss 3.1802e-01 (3.3194e-01)
Epoch: [1][2000/3491]	Time  0.483 ( 1.429)	Loss 3.1465e-01 (3.3195e-01)
Epoch: [1][2050/3491]	Time  6.768 ( 1.436)	Loss 3.2480e-01 (3.3193e-01)
Epoch: [1][2100/3491]	Time  2.877 ( 1.439)	Loss 3.0804e-01 (3.3204e-01)
Epoch: [1][2150/3491]	Time  0.483 ( 1.442)	Loss 3.4547e-01 (3.3206e-01)
Epoch: [1][2200/3491]	Time  0.483 ( 1.445)	Loss 3.5186e-01 (3.3200e-01)
Epoch: [1][2250/3491]	Time  5.913 ( 1.452)	Loss 3.3192e-01 (3.3195e-01)
Epoch: [1][2300/3491]	Time  0.483 ( 1.456)	Loss 3.1531e-01 (3.3201e-01)
Epoch: [1][2350/3491]	Time  0.483 ( 1.457)	Loss 3.2840e-01 (3.3195e-01)
Epoch: [1][2400/3491]	Time  0.483 ( 1.458)	Loss 2.9670e-01 (3.3193e-01)
Epoch: [1][2450/3491]	Time  8.313 ( 1.463)	Loss 3.2476e-01 (3.3192e-01)
Epoch: [1][2500/3491]	Time  0.483 ( 1.463)	Loss 3.5655e-01 (3.3196e-01)
Epoch: [1][2550/3491]	Time  0.483 ( 1.463)	Loss 2.9830e-01 (3.3190e-01)
Epoch: [1][2600/3491]	Time  0.483 ( 1.465)	Loss 3.3266e-01 (3.3187e-01)
Epoch: [1][2650/3491]	Time  9.250 ( 1.468)	Loss 3.4644e-01 (3.3182e-01)
Epoch: [1][2700/3491]	Time  0.483 ( 1.468)	Loss 3.3674e-01 (3.3178e-01)
Epoch: [1][2750/3491]	Time  0.483 ( 1.469)	Loss 3.4022e-01 (3.3176e-01)
Epoch: [1][2800/3491]	Time  0.483 ( 1.469)	Loss 3.2606e-01 (3.3171e-01)
Epoch: [1][2850/3491]	Time  8.395 ( 1.471)	Loss 3.2033e-01 (3.3162e-01)
Epoch: [1][2900/3491]	Time  1.249 ( 1.471)	Loss 2.9120e-01 (3.3166e-01)
Epoch: [1][2950/3491]	Time  0.483 ( 1.471)	Loss 3.7279e-01 (3.3169e-01)
Epoch: [1][3000/3491]	Time  0.483 ( 1.472)	Loss 3.7638e-01 (3.3174e-01)
Epoch: [1][3050/3491]	Time  8.382 ( 1.474)	Loss 3.2619e-01 (3.3167e-01)
Epoch: [1][3100/3491]	Time  0.483 ( 1.474)	Loss 3.3277e-01 (3.3162e-01)
Epoch: [1][3150/3491]	Time  0.483 ( 1.476)	Loss 3.2317e-01 (3.3161e-01)
Epoch: [1][3200/3491]	Time  0.483 ( 1.478)	Loss 3.4730e-01 (3.3160e-01)
Epoch: [1][3250/3491]	Time  7.632 ( 1.481)	Loss 3.1760e-01 (3.3160e-01)
Epoch: [1][3300/3491]	Time  2.845 ( 1.483)	Loss 3.6792e-01 (3.3162e-01)
Epoch: [1][3350/3491]	Time  0.483 ( 1.484)	Loss 3.1463e-01 (3.3167e-01)
Epoch: [1][3400/3491]	Time  0.483 ( 1.485)	Loss 3.3114e-01 (3.3167e-01)
Epoch: [1][3450/3491]	Time  7.574 ( 1.489)	Loss 3.0338e-01 (3.3163e-01)
Val: [0/4]	Time 12.212 (12.212)	Loss 2.7866e-01 (2.7866e-01)
Epoch 0001: val_loss did not improve from 0.33646 
Epoch: [2][   0/3491]	Time 12.948 (12.948)	Loss 3.3021e-01 (3.3021e-01)
Epoch: [2][  50/3491]	Time  0.483 ( 1.730)	Loss 3.3562e-01 (3.3039e-01)
Epoch: [2][ 100/3491]	Time  0.483 ( 1.608)	Loss 3.3399e-01 (3.3141e-01)
Epoch: [2][ 150/3491]	Time  0.483 ( 1.590)	Loss 3.1745e-01 (3.3065e-01)
Epoch: [2][ 200/3491]	Time  3.003 ( 1.594)	Loss 3.3502e-01 (3.2959e-01)
Epoch: [2][ 250/3491]	Time  0.483 ( 1.598)	Loss 3.0082e-01 (3.2932e-01)
Epoch: [2][ 300/3491]	Time  0.483 ( 1.597)	Loss 3.7385e-01 (3.2992e-01)
Epoch: [2][ 350/3491]	Time  0.483 ( 1.587)	Loss 3.1924e-01 (3.2987e-01)
Epoch: [2][ 400/3491]	Time  1.987 ( 1.587)	Loss 3.2150e-01 (3.3006e-01)
Epoch: [2][ 450/3491]	Time  1.560 ( 1.610)	Loss 3.4914e-01 (3.2937e-01)
Epoch: [2][ 500/3491]	Time  0.483 ( 1.605)	Loss 3.4251e-01 (3.3005e-01)
Epoch: [2][ 550/3491]	Time  0.483 ( 1.599)	Loss 3.3932e-01 (3.3032e-01)
Epoch: [2][ 600/3491]	Time  0.483 ( 1.596)	Loss 3.4290e-01 (3.3030e-01)
Epoch: [2][ 650/3491]	Time  1.123 ( 1.607)	Loss 3.3554e-01 (3.3039e-01)
Epoch: [2][ 700/3491]	Time  0.483 ( 1.603)	Loss 3.1159e-01 (3.3062e-01)
Epoch: [2][ 750/3491]	Time  0.483 ( 1.598)	Loss 3.0942e-01 (3.3070e-01)
Epoch: [2][ 800/3491]	Time  0.483 ( 1.594)	Loss 3.3816e-01 (3.3066e-01)
Epoch: [2][ 850/3491]	Time  0.483 ( 1.598)	Loss 3.1958e-01 (3.3035e-01)
Epoch: [2][ 900/3491]	Time  0.483 ( 1.595)	Loss 3.2953e-01 (3.3057e-01)
Epoch: [2][ 950/3491]	Time  0.483 ( 1.591)	Loss 3.1989e-01 (3.3050e-01)
Epoch: [2][1000/3491]	Time  0.483 ( 1.590)	Loss 3.3545e-01 (3.3064e-01)
Epoch: [2][1050/3491]	Time  0.483 ( 1.597)	Loss 3.0150e-01 (3.3055e-01)
Epoch: [2][1100/3491]	Time  0.483 ( 1.595)	Loss 3.3683e-01 (3.3031e-01)
Epoch: [2][1150/3491]	Time  3.292 ( 1.593)	Loss 3.3649e-01 (3.3022e-01)
Epoch: [2][1200/3491]	Time  0.483 ( 1.590)	Loss 3.2108e-01 (3.3008e-01)
Epoch: [2][1250/3491]	Time  0.483 ( 1.593)	Loss 3.8927e-01 (3.3011e-01)
Epoch: [2][1300/3491]	Time  0.483 ( 1.594)	Loss 3.1329e-01 (3.3002e-01)
Epoch: [2][1350/3491]	Time  2.239 ( 1.592)	Loss 3.1608e-01 (3.3004e-01)
Epoch: [2][1400/3491]	Time  0.483 ( 1.591)	Loss 3.0702e-01 (3.3006e-01)
Epoch: [2][1450/3491]	Time  0.483 ( 1.594)	Loss 3.1775e-01 (3.3005e-01)
Epoch: [2][1500/3491]	Time  0.483 ( 1.591)	Loss 3.3887e-01 (3.3013e-01)
Epoch: [2][1550/3491]	Time  3.514 ( 1.589)	Loss 3.2668e-01 (3.3013e-01)
Epoch: [2][1600/3491]	Time  0.483 ( 1.585)	Loss 3.7978e-01 (3.3010e-01)
Epoch: [2][1650/3491]	Time  0.483 ( 1.587)	Loss 3.2310e-01 (3.3025e-01)
Epoch: [2][1700/3491]	Time  0.483 ( 1.583)	Loss 2.9651e-01 (3.3032e-01)
Epoch: [2][1750/3491]	Time  0.483 ( 1.580)	Loss 3.1817e-01 (3.3033e-01)
Epoch: [2][1800/3491]	Time  0.483 ( 1.578)	Loss 3.2941e-01 (3.3034e-01)
Epoch: [2][1850/3491]	Time  0.483 ( 1.581)	Loss 3.2308e-01 (3.3033e-01)
Epoch: [2][1900/3491]	Time  0.483 ( 1.580)	Loss 3.1875e-01 (3.3041e-01)
Epoch: [2][1950/3491]	Time  0.483 ( 1.580)	Loss 3.5928e-01 (3.3040e-01)
Epoch: [2][2000/3491]	Time  0.483 ( 1.579)	Loss 3.0571e-01 (3.3033e-01)
Epoch: [2][2050/3491]	Time  0.483 ( 1.583)	Loss 3.4531e-01 (3.3027e-01)
Epoch: [2][2100/3491]	Time  0.483 ( 1.583)	Loss 3.0850e-01 (3.3018e-01)
Epoch: [2][2150/3491]	Time  0.483 ( 1.581)	Loss 3.2837e-01 (3.3022e-01)
Epoch: [2][2200/3491]	Time  0.483 ( 1.581)	Loss 3.1653e-01 (3.3019e-01)
Epoch: [2][2250/3491]	Time  0.483 ( 1.584)	Loss 3.2204e-01 (3.3021e-01)
Epoch: [2][2300/3491]	Time  0.483 ( 1.585)	Loss 3.4838e-01 (3.3027e-01)
Epoch: [2][2350/3491]	Time  0.483 ( 1.588)	Loss 3.2081e-01 (3.3016e-01)
Epoch: [2][2400/3491]	Time  0.483 ( 1.588)	Loss 3.3582e-01 (3.3012e-01)
Epoch: [2][2450/3491]	Time  0.483 ( 1.592)	Loss 3.2141e-01 (3.3002e-01)
Epoch: [2][2500/3491]	Time  0.483 ( 1.591)	Loss 3.0589e-01 (3.3003e-01)
Epoch: [2][2550/3491]	Time  0.483 ( 1.591)	Loss 3.4121e-01 (3.3000e-01)
Epoch: [2][2600/3491]	Time  0.483 ( 1.590)	Loss 2.9994e-01 (3.3004e-01)
Epoch: [2][2650/3491]	Time  0.483 ( 1.592)	Loss 3.4732e-01 (3.3001e-01)
Epoch: [2][2700/3491]	Time  0.483 ( 1.593)	Loss 3.2838e-01 (3.2994e-01)
Epoch: [2][2750/3491]	Time  0.483 ( 1.592)	Loss 2.9789e-01 (3.2985e-01)
Epoch: [2][2800/3491]	Time  0.483 ( 1.593)	Loss 3.2378e-01 (3.2988e-01)
Epoch: [2][2850/3491]	Time  0.483 ( 1.597)	Loss 3.0563e-01 (3.2993e-01)
Epoch: [2][2900/3491]	Time  0.483 ( 1.596)	Loss 3.0501e-01 (3.2997e-01)
Epoch: [2][2950/3491]	Time  0.483 ( 1.596)	Loss 3.0698e-01 (3.2995e-01)
Epoch: [2][3000/3491]	Time  0.483 ( 1.595)	Loss 3.0945e-01 (3.2991e-01)
Epoch: [2][3050/3491]	Time  0.483 ( 1.599)	Loss 3.2084e-01 (3.2988e-01)
Epoch: [2][3100/3491]	Time  0.483 ( 1.599)	Loss 3.2044e-01 (3.2985e-01)
Epoch: [2][3150/3491]	Time  0.483 ( 1.598)	Loss 3.2869e-01 (3.2993e-01)
Epoch: [2][3200/3491]	Time  0.483 ( 1.598)	Loss 3.3590e-01 (3.2995e-01)
Epoch: [2][3250/3491]	Time  0.483 ( 1.601)	Loss 2.9393e-01 (3.2995e-01)
Epoch: [2][3300/3491]	Time  0.483 ( 1.602)	Loss 3.5354e-01 (3.2998e-01)
Epoch: [2][3350/3491]	Time  0.483 ( 1.602)	Loss 3.2870e-01 (3.2999e-01)
Epoch: [2][3400/3491]	Time  0.483 ( 1.602)	Loss 3.3605e-01 (3.2994e-01)
Epoch: [2][3450/3491]	Time  0.483 ( 1.605)	Loss 3.1306e-01 (3.2986e-01)
Val: [0/4]	Time 12.680 (12.680)	Loss 2.7901e-01 (2.7901e-01)
Epoch 0002: val_loss did not improve from 0.33646 
Epoch: [3][   0/3491]	Time 12.455 (12.455)	Loss 3.2876e-01 (3.2876e-01)
Epoch: [3][  50/3491]	Time  0.483 ( 1.573)	Loss 3.3953e-01 (3.3272e-01)
Epoch: [3][ 100/3491]	Time  0.483 ( 1.450)	Loss 3.3118e-01 (3.3247e-01)
Epoch: [3][ 150/3491]	Time  0.483 ( 1.405)	Loss 3.3894e-01 (3.3067e-01)
Epoch: [3][ 200/3491]	Time  1.858 ( 1.409)	Loss 3.1093e-01 (3.2969e-01)
Epoch: [3][ 250/3491]	Time  0.483 ( 1.402)	Loss 3.2645e-01 (3.2925e-01)
Epoch: [3][ 300/3491]	Time  0.483 ( 1.410)	Loss 3.0916e-01 (3.2879e-01)
Epoch: [3][ 350/3491]	Time  0.483 ( 1.408)	Loss 3.2589e-01 (3.2906e-01)
Epoch: [3][ 400/3491]	Time  3.653 ( 1.409)	Loss 3.2346e-01 (3.2924e-01)
Epoch: [3][ 450/3491]	Time  0.483 ( 1.413)	Loss 3.3215e-01 (3.2910e-01)
Epoch: [3][ 500/3491]	Time  0.483 ( 1.415)	Loss 3.4708e-01 (3.2944e-01)
Epoch: [3][ 550/3491]	Time  0.483 ( 1.416)	Loss 3.5073e-01 (3.2944e-01)
Epoch: [3][ 600/3491]	Time  0.483 ( 1.419)	Loss 3.3741e-01 (3.2956e-01)
Epoch: [3][ 650/3491]	Time  0.483 ( 1.425)	Loss 3.5538e-01 (3.2928e-01)
Epoch: [3][ 700/3491]	Time  0.483 ( 1.425)	Loss 3.3084e-01 (3.2921e-01)
Epoch: [3][ 750/3491]	Time  0.483 ( 1.430)	Loss 3.5073e-01 (3.2928e-01)
Epoch: [3][ 800/3491]	Time  1.187 ( 1.428)	Loss 3.2575e-01 (3.2925e-01)
Epoch: [3][ 850/3491]	Time  0.483 ( 1.436)	Loss 2.9950e-01 (3.2920e-01)
Epoch: [3][ 900/3491]	Time  2.508 ( 1.439)	Loss 2.9996e-01 (3.2898e-01)
Epoch: [3][ 950/3491]	Time  0.483 ( 1.446)	Loss 3.0945e-01 (3.2889e-01)
Epoch: [3][1000/3491]	Time  0.483 ( 1.450)	Loss 3.4804e-01 (3.2879e-01)
Epoch: [3][1050/3491]	Time  0.483 ( 1.452)	Loss 3.2025e-01 (3.2880e-01)
Epoch: [3][1100/3491]	Time  6.185 ( 1.459)	Loss 3.2226e-01 (3.2875e-01)
Epoch: [3][1150/3491]	Time  0.483 ( 1.462)	Loss 3.1792e-01 (3.2866e-01)
Epoch: [3][1200/3491]	Time  1.531 ( 1.466)	Loss 3.2776e-01 (3.2858e-01)
Epoch: [3][1250/3491]	Time  0.483 ( 1.474)	Loss 3.4730e-01 (3.2861e-01)
Epoch: [3][1300/3491]	Time  5.317 ( 1.486)	Loss 3.4207e-01 (3.2861e-01)
Epoch: [3][1350/3491]	Time  0.483 ( 1.495)	Loss 3.0667e-01 (3.2848e-01)
Epoch: [3][1400/3491]	Time  3.582 ( 1.504)	Loss 2.8430e-01 (3.2852e-01)
Epoch: [3][1450/3491]	Time  0.483 ( 1.507)	Loss 3.1585e-01 (3.2845e-01)
Epoch: [3][1500/3491]	Time  6.693 ( 1.518)	Loss 3.4250e-01 (3.2848e-01)
Epoch: [3][1550/3491]	Time  0.483 ( 1.523)	Loss 3.1635e-01 (3.2854e-01)
Epoch: [3][1600/3491]	Time  7.922 ( 1.531)	Loss 3.1613e-01 (3.2859e-01)
Epoch: [3][1650/3491]	Time  0.483 ( 1.533)	Loss 3.3117e-01 (3.2873e-01)
Epoch: [3][1700/3491]	Time  0.483 ( 1.537)	Loss 3.2266e-01 (3.2870e-01)
Epoch: [3][1750/3491]	Time  0.483 ( 1.552)	Loss 3.4664e-01 (3.2860e-01)
Epoch: [3][1800/3491]	Time 12.810 ( 1.581)	Loss 3.3275e-01 (3.2861e-01)
Epoch: [3][1850/3491]	Time  0.483 ( 1.585)	Loss 2.8650e-01 (3.2867e-01)
Epoch: [3][1900/3491]	Time  0.483 ( 1.585)	Loss 3.3736e-01 (3.2855e-01)
Epoch: [3][1950/3491]	Time  0.483 ( 1.587)	Loss 3.2918e-01 (3.2845e-01)
Epoch: [3][2000/3491]	Time  9.308 ( 1.588)	Loss 3.0739e-01 (3.2844e-01)
Epoch: [3][2050/3491]	Time  0.483 ( 1.585)	Loss 3.2905e-01 (3.2855e-01)
Epoch: [3][2100/3491]	Time  0.483 ( 1.582)	Loss 3.3182e-01 (3.2855e-01)
Epoch: [3][2150/3491]	Time  0.483 ( 1.580)	Loss 3.1978e-01 (3.2853e-01)
Epoch: [3][2200/3491]	Time  9.647 ( 1.582)	Loss 3.2118e-01 (3.2844e-01)
Epoch: [3][2250/3491]	Time  0.483 ( 1.581)	Loss 2.8452e-01 (3.2846e-01)
Epoch: [3][2300/3491]	Time  0.483 ( 1.578)	Loss 3.8066e-01 (3.2847e-01)
Epoch: [3][2350/3491]	Time  0.483 ( 1.575)	Loss 3.5990e-01 (3.2846e-01)
Epoch: [3][2400/3491]	Time  8.543 ( 1.576)	Loss 3.6016e-01 (3.2854e-01)
Epoch: [3][2450/3491]	Time  0.483 ( 1.574)	Loss 3.3557e-01 (3.2845e-01)
Epoch: [3][2500/3491]	Time  0.483 ( 1.571)	Loss 3.2367e-01 (3.2845e-01)
Epoch: [3][2550/3491]	Time  0.483 ( 1.569)	Loss 3.3445e-01 (3.2847e-01)
Epoch: [3][2600/3491]	Time  8.337 ( 1.570)	Loss 3.4702e-01 (3.2858e-01)
Epoch: [3][2650/3491]	Time  0.483 ( 1.568)	Loss 3.4369e-01 (3.2863e-01)
Epoch: [3][2700/3491]	Time  0.483 ( 1.566)	Loss 2.9655e-01 (3.2861e-01)
Epoch: [3][2750/3491]	Time  0.483 ( 1.565)	Loss 3.0497e-01 (3.2862e-01)
Epoch: [3][2800/3491]	Time  9.653 ( 1.568)	Loss 3.3924e-01 (3.2867e-01)
Epoch: [3][2850/3491]	Time  0.483 ( 1.569)	Loss 3.0876e-01 (3.2862e-01)
Epoch: [3][2900/3491]	Time  0.483 ( 1.568)	Loss 3.2152e-01 (3.2865e-01)
Epoch: [3][2950/3491]	Time  0.483 ( 1.567)	Loss 3.5888e-01 (3.2869e-01)
Epoch: [3][3000/3491]	Time  9.184 ( 1.570)	Loss 3.4228e-01 (3.2873e-01)
Epoch: [3][3050/3491]	Time  0.483 ( 1.568)	Loss 3.3707e-01 (3.2864e-01)
Epoch: [3][3100/3491]	Time  0.483 ( 1.568)	Loss 3.3360e-01 (3.2863e-01)
Epoch: [3][3150/3491]	Time  0.483 ( 1.567)	Loss 3.3072e-01 (3.2855e-01)
Epoch: [3][3200/3491]	Time  9.375 ( 1.568)	Loss 3.3760e-01 (3.2859e-01)
Epoch: [3][3250/3491]	Time  0.483 ( 1.567)	Loss 3.7052e-01 (3.2859e-01)
Epoch: [3][3300/3491]	Time  0.483 ( 1.566)	Loss 3.2355e-01 (3.2855e-01)
Epoch: [3][3350/3491]	Time  0.483 ( 1.566)	Loss 3.5567e-01 (3.2859e-01)
Epoch: [3][3400/3491]	Time  9.794 ( 1.567)	Loss 2.9638e-01 (3.2856e-01)
Epoch: [3][3450/3491]	Time  0.483 ( 1.567)	Loss 3.2238e-01 (3.2856e-01)
Val: [0/4]	Time 12.647 (12.647)	Loss 2.8336e-01 (2.8336e-01)
Epoch 0003: val_loss did not improve from 0.33646 
Epoch: [4][   0/3491]	Time 12.769 (12.769)	Loss 3.0646e-01 (3.0646e-01)
Epoch: [4][  50/3491]	Time  0.483 ( 1.608)	Loss 3.5786e-01 (3.2544e-01)
Epoch: [4][ 100/3491]	Time  0.483 ( 1.504)	Loss 3.3499e-01 (3.2608e-01)
Epoch: [4][ 150/3491]	Time  0.483 ( 1.434)	Loss 3.3300e-01 (3.2663e-01)
Epoch: [4][ 200/3491]	Time  7.233 ( 1.439)	Loss 3.5658e-01 (3.2734e-01)
Epoch: [4][ 250/3491]	Time  0.483 ( 1.422)	Loss 3.5193e-01 (3.2788e-01)
Epoch: [4][ 300/3491]	Time  0.483 ( 1.406)	Loss 3.3238e-01 (3.2808e-01)
Epoch: [4][ 350/3491]	Time  0.483 ( 1.403)	Loss 3.3390e-01 (3.2809e-01)
Epoch: [4][ 400/3491]	Time  6.421 ( 1.412)	Loss 3.4431e-01 (3.2797e-01)
Epoch: [4][ 450/3491]	Time  0.483 ( 1.404)	Loss 3.2946e-01 (3.2837e-01)
Epoch: [4][ 500/3491]	Time  0.483 ( 1.397)	Loss 3.2239e-01 (3.2824e-01)
Epoch: [4][ 550/3491]	Time  0.483 ( 1.397)	Loss 3.0085e-01 (3.2797e-01)
Epoch: [4][ 600/3491]	Time  8.294 ( 1.412)	Loss 3.2307e-01 (3.2787e-01)
Epoch: [4][ 650/3491]	Time  0.483 ( 1.420)	Loss 3.0534e-01 (3.2789e-01)
Epoch: [4][ 700/3491]	Time  0.483 ( 1.428)	Loss 3.3078e-01 (3.2819e-01)
Epoch: [4][ 750/3491]	Time  0.483 ( 1.433)	Loss 3.0665e-01 (3.2834e-01)
Epoch: [4][ 800/3491]	Time 10.267 ( 1.456)	Loss 3.4654e-01 (3.2862e-01)
Epoch: [4][ 850/3491]	Time  0.483 ( 1.463)	Loss 3.1647e-01 (3.2851e-01)
Epoch: [4][ 900/3491]	Time  0.483 ( 1.463)	Loss 3.3020e-01 (3.2864e-01)
Epoch: [4][ 950/3491]	Time  0.483 ( 1.467)	Loss 3.4828e-01 (3.2846e-01)
Epoch: [4][1000/3491]	Time 10.349 ( 1.480)	Loss 3.5886e-01 (3.2843e-01)
Epoch: [4][1050/3491]	Time  0.483 ( 1.487)	Loss 3.2816e-01 (3.2858e-01)
Epoch: [4][1100/3491]	Time  0.483 ( 1.491)	Loss 3.2533e-01 (3.2846e-01)
Epoch: [4][1150/3491]	Time  0.483 ( 1.495)	Loss 3.4956e-01 (3.2849e-01)
Epoch: [4][1200/3491]	Time 10.774 ( 1.510)	Loss 3.4834e-01 (3.2852e-01)
Epoch: [4][1250/3491]	Time  0.483 ( 1.512)	Loss 3.5026e-01 (3.2856e-01)
Epoch: [4][1300/3491]	Time  0.483 ( 1.513)	Loss 3.5071e-01 (3.2839e-01)
Epoch: [4][1350/3491]	Time  0.483 ( 1.517)	Loss 3.1516e-01 (3.2832e-01)
Epoch: [4][1400/3491]	Time  8.365 ( 1.527)	Loss 3.1192e-01 (3.2824e-01)
Epoch: [4][1450/3491]	Time  0.483 ( 1.528)	Loss 3.4133e-01 (3.2821e-01)
Epoch: [4][1500/3491]	Time  0.483 ( 1.525)	Loss 3.2564e-01 (3.2838e-01)
Epoch: [4][1550/3491]	Time  0.483 ( 1.522)	Loss 3.3050e-01 (3.2844e-01)
Epoch: [4][1600/3491]	Time  8.636 ( 1.524)	Loss 3.4651e-01 (3.2842e-01)
Epoch: [4][1650/3491]	Time  0.483 ( 1.522)	Loss 2.8003e-01 (3.2828e-01)
Epoch: [4][1700/3491]	Time  0.483 ( 1.519)	Loss 3.3878e-01 (3.2808e-01)
Epoch: [4][1750/3491]	Time  0.483 ( 1.517)	Loss 3.4676e-01 (3.2809e-01)
Epoch: [4][1800/3491]	Time  5.937 ( 1.519)	Loss 2.8700e-01 (3.2823e-01)
Epoch: [4][1850/3491]	Time  0.483 ( 1.519)	Loss 3.6155e-01 (3.2829e-01)
Epoch: [4][1900/3491]	Time  0.483 ( 1.520)	Loss 3.0898e-01 (3.2825e-01)
Epoch: [4][1950/3491]	Time  4.644 ( 1.521)	Loss 3.2577e-01 (3.2824e-01)
Epoch: [4][2000/3491]	Time  4.275 ( 1.521)	Loss 3.1476e-01 (3.2813e-01)
Epoch: [4][2050/3491]	Time  2.071 ( 1.520)	Loss 3.0631e-01 (3.2819e-01)
Epoch: [4][2100/3491]	Time  0.483 ( 1.518)	Loss 3.2215e-01 (3.2825e-01)
Epoch: [4][2150/3491]	Time  2.768 ( 1.518)	Loss 3.4768e-01 (3.2826e-01)
Epoch: [4][2200/3491]	Time  6.911 ( 1.520)	Loss 3.0950e-01 (3.2817e-01)
Epoch: [4][2250/3491]	Time  0.483 ( 1.519)	Loss 3.2788e-01 (3.2814e-01)
Epoch: [4][2300/3491]	Time  0.905 ( 1.519)	Loss 3.5350e-01 (3.2820e-01)
Epoch: [4][2350/3491]	Time  1.564 ( 1.519)	Loss 3.0796e-01 (3.2822e-01)
Epoch: [4][2400/3491]	Time  5.284 ( 1.520)	Loss 3.5413e-01 (3.2823e-01)
Epoch: [4][2450/3491]	Time  0.483 ( 1.521)	Loss 3.3252e-01 (3.2821e-01)
Epoch: [4][2500/3491]	Time  1.665 ( 1.522)	Loss 3.3093e-01 (3.2821e-01)
Epoch: [4][2550/3491]	Time  2.157 ( 1.523)	Loss 3.7764e-01 (3.2816e-01)
Epoch: [4][2600/3491]	Time  2.408 ( 1.524)	Loss 3.2923e-01 (3.2799e-01)
Epoch: [4][2650/3491]	Time  0.483 ( 1.525)	Loss 3.3832e-01 (3.2796e-01)
Epoch: [4][2700/3491]	Time 11.004 ( 1.529)	Loss 3.2756e-01 (3.2794e-01)
Epoch: [4][2750/3491]	Time  0.483 ( 1.530)	Loss 3.1264e-01 (3.2795e-01)
Epoch: [4][2800/3491]	Time  0.483 ( 1.530)	Loss 3.6102e-01 (3.2801e-01)
Epoch: [4][2850/3491]	Time  0.483 ( 1.533)	Loss 3.2916e-01 (3.2792e-01)
Epoch: [4][2900/3491]	Time  8.904 ( 1.536)	Loss 3.3606e-01 (3.2788e-01)
Epoch: [4][2950/3491]	Time  0.483 ( 1.535)	Loss 3.0541e-01 (3.2784e-01)
Epoch: [4][3000/3491]	Time  0.484 ( 1.535)	Loss 2.7500e-01 (3.2781e-01)
Epoch: [4][3050/3491]	Time  0.483 ( 1.536)	Loss 3.3405e-01 (3.2779e-01)
Epoch: [4][3100/3491]	Time 10.036 ( 1.539)	Loss 3.0421e-01 (3.2779e-01)
Epoch: [4][3150/3491]	Time  0.483 ( 1.539)	Loss 3.3756e-01 (3.2777e-01)
Epoch: [4][3200/3491]	Time  0.484 ( 1.539)	Loss 3.1310e-01 (3.2777e-01)
Epoch: [4][3250/3491]	Time  0.483 ( 1.539)	Loss 3.1067e-01 (3.2777e-01)
Epoch: [4][3300/3491]	Time  9.057 ( 1.541)	Loss 3.3004e-01 (3.2776e-01)
Epoch: [4][3350/3491]	Time  0.483 ( 1.540)	Loss 3.1981e-01 (3.2768e-01)
Epoch: [4][3400/3491]	Time  0.483 ( 1.539)	Loss 3.3303e-01 (3.2770e-01)
Epoch: [4][3450/3491]	Time  0.483 ( 1.539)	Loss 3.3286e-01 (3.2766e-01)
Val: [0/4]	Time 11.745 (11.745)	Loss 2.8637e-01 (2.8637e-01)
Epoch 0004: val_loss did not improve from 0.33646 
Epoch: [5][   0/3491]	Time 11.133 (11.133)	Loss 3.1506e-01 (3.1506e-01)
Epoch: [5][  50/3491]	Time  2.080 ( 1.433)	Loss 3.4346e-01 (3.2289e-01)
Epoch: [5][ 100/3491]	Time  0.483 ( 1.323)	Loss 3.0832e-01 (3.2657e-01)
Epoch: [5][ 150/3491]	Time  0.483 ( 1.306)	Loss 3.3503e-01 (3.2783e-01)
Epoch: [5][ 200/3491]	Time  4.963 ( 1.314)	Loss 3.3000e-01 (3.2722e-01)
Epoch: [5][ 250/3491]	Time  0.483 ( 1.307)	Loss 3.3051e-01 (3.2764e-01)
Epoch: [5][ 300/3491]	Time  0.483 ( 1.303)	Loss 3.2071e-01 (3.2721e-01)
Epoch: [5][ 350/3491]	Time  0.483 ( 1.306)	Loss 2.9689e-01 (3.2668e-01)
Epoch: [5][ 400/3491]	Time  7.623 ( 1.324)	Loss 3.1874e-01 (3.2694e-01)
Epoch: [5][ 450/3491]	Time  0.483 ( 1.325)	Loss 3.4245e-01 (3.2714e-01)
Epoch: [5][ 500/3491]	Time  0.483 ( 1.330)	Loss 3.2855e-01 (3.2706e-01)
Epoch: [5][ 550/3491]	Time  0.483 ( 1.333)	Loss 3.1374e-01 (3.2693e-01)
Epoch: [5][ 600/3491]	Time  3.927 ( 1.342)	Loss 3.4547e-01 (3.2716e-01)
Epoch: [5][ 650/3491]	Time  0.483 ( 1.351)	Loss 3.4919e-01 (3.2702e-01)
Epoch: [5][ 700/3491]	Time  0.483 ( 1.355)	Loss 3.5071e-01 (3.2674e-01)
Epoch: [5][ 750/3491]	Time  0.483 ( 1.357)	Loss 3.1381e-01 (3.2684e-01)
Epoch: [5][ 800/3491]	Time  5.459 ( 1.367)	Loss 3.2383e-01 (3.2685e-01)
Epoch: [5][ 850/3491]	Time  0.483 ( 1.371)	Loss 3.6830e-01 (3.2699e-01)
Epoch: [5][ 900/3491]	Time  0.483 ( 1.380)	Loss 2.8986e-01 (3.2688e-01)
Epoch: [5][ 950/3491]	Time  0.483 ( 1.388)	Loss 3.3404e-01 (3.2702e-01)
Epoch: [5][1000/3491]	Time  0.483 ( 1.395)	Loss 3.1252e-01 (3.2703e-01)
Epoch: [5][1050/3491]	Time  0.483 ( 1.402)	Loss 3.6287e-01 (3.2695e-01)
Epoch: [5][1100/3491]	Time  0.483 ( 1.414)	Loss 3.1333e-01 (3.2687e-01)
Epoch: [5][1150/3491]	Time  0.483 ( 1.420)	Loss 3.1002e-01 (3.2678e-01)
Epoch: [5][1200/3491]	Time  0.483 ( 1.424)	Loss 3.1516e-01 (3.2669e-01)
Epoch: [5][1250/3491]	Time  0.483 ( 1.432)	Loss 3.3764e-01 (3.2669e-01)
Epoch: [5][1300/3491]	Time  0.483 ( 1.444)	Loss 3.4393e-01 (3.2678e-01)
Epoch: [5][1350/3491]	Time  0.483 ( 1.448)	Loss 3.0596e-01 (3.2688e-01)
Epoch: [5][1400/3491]	Time  0.483 ( 1.452)	Loss 3.5641e-01 (3.2699e-01)
Epoch: [5][1450/3491]	Time  0.483 ( 1.456)	Loss 3.1306e-01 (3.2682e-01)
Epoch: [5][1500/3491]	Time  0.483 ( 1.464)	Loss 3.0541e-01 (3.2670e-01)
Epoch: [5][1550/3491]	Time  0.483 ( 1.469)	Loss 3.5811e-01 (3.2671e-01)
Epoch: [5][1600/3491]	Time  0.723 ( 1.472)	Loss 3.0911e-01 (3.2675e-01)
Epoch: [5][1650/3491]	Time  0.483 ( 1.476)	Loss 3.5996e-01 (3.2668e-01)
Epoch: [5][1700/3491]	Time  0.483 ( 1.482)	Loss 3.4154e-01 (3.2675e-01)
Epoch: [5][1750/3491]	Time  0.483 ( 1.483)	Loss 3.6688e-01 (3.2684e-01)
Epoch: [5][1800/3491]	Time  0.483 ( 1.486)	Loss 3.0575e-01 (3.2673e-01)
Epoch: [5][1850/3491]	Time  0.483 ( 1.488)	Loss 3.3162e-01 (3.2674e-01)
Epoch: [5][1900/3491]	Time  0.484 ( 1.496)	Loss 3.3184e-01 (3.2666e-01)
Epoch: [5][1950/3491]	Time  0.483 ( 1.497)	Loss 3.0185e-01 (3.2662e-01)
Epoch: [5][2000/3491]	Time  0.483 ( 1.500)	Loss 3.3902e-01 (3.2659e-01)
Epoch: [5][2050/3491]	Time  0.483 ( 1.501)	Loss 3.3025e-01 (3.2672e-01)
Epoch: [5][2100/3491]	Time  0.483 ( 1.506)	Loss 3.7000e-01 (3.2663e-01)
Epoch: [5][2150/3491]	Time  0.483 ( 1.509)	Loss 3.2716e-01 (3.2664e-01)
Epoch: [5][2200/3491]	Time  0.483 ( 1.511)	Loss 3.2931e-01 (3.2666e-01)
Epoch: [5][2250/3491]	Time  0.483 ( 1.513)	Loss 3.5209e-01 (3.2671e-01)
Epoch: [5][2300/3491]	Time  0.484 ( 1.517)	Loss 3.1953e-01 (3.2668e-01)
Epoch: [5][2350/3491]	Time  0.483 ( 1.518)	Loss 3.1494e-01 (3.2660e-01)
Epoch: [5][2400/3491]	Time  0.483 ( 1.518)	Loss 3.1456e-01 (3.2658e-01)
Epoch: [5][2450/3491]	Time  0.483 ( 1.519)	Loss 3.3868e-01 (3.2659e-01)
Epoch: [5][2500/3491]	Time  0.483 ( 1.524)	Loss 3.2444e-01 (3.2668e-01)
Epoch: [5][2550/3491]	Time  0.483 ( 1.526)	Loss 3.2872e-01 (3.2660e-01)
Epoch: [5][2600/3491]	Time  0.483 ( 1.528)	Loss 3.2666e-01 (3.2659e-01)
Epoch: [5][2650/3491]	Time  0.483 ( 1.529)	Loss 3.1020e-01 (3.2666e-01)
Epoch: [5][2700/3491]	Time  0.483 ( 1.530)	Loss 3.0962e-01 (3.2666e-01)
Epoch: [5][2750/3491]	Time  0.483 ( 1.534)	Loss 3.3589e-01 (3.2670e-01)
Epoch: [5][2800/3491]	Time  0.483 ( 1.535)	Loss 3.1935e-01 (3.2668e-01)
Epoch: [5][2850/3491]	Time  0.483 ( 1.536)	Loss 3.4731e-01 (3.2671e-01)
Epoch: [5][2900/3491]	Time  0.483 ( 1.537)	Loss 3.5674e-01 (3.2667e-01)
Epoch: [5][2950/3491]	Time  0.483 ( 1.541)	Loss 3.4032e-01 (3.2662e-01)
Epoch: [5][3000/3491]	Time  0.483 ( 1.543)	Loss 3.2743e-01 (3.2667e-01)
Epoch: [5][3050/3491]	Time  0.483 ( 1.544)	Loss 3.5925e-01 (3.2671e-01)
Epoch: [5][3100/3491]	Time  0.483 ( 1.545)	Loss 3.1088e-01 (3.2681e-01)
Epoch: [5][3150/3491]	Time  0.483 ( 1.549)	Loss 3.3061e-01 (3.2682e-01)
Epoch: [5][3200/3491]	Time  0.483 ( 1.549)	Loss 3.4225e-01 (3.2683e-01)
Epoch: [5][3250/3491]	Time  0.483 ( 1.550)	Loss 3.1780e-01 (3.2689e-01)
Epoch: [5][3300/3491]	Time  0.483 ( 1.551)	Loss 3.2866e-01 (3.2693e-01)
Epoch: [5][3350/3491]	Time  0.483 ( 1.554)	Loss 3.1616e-01 (3.2696e-01)
Epoch: [5][3400/3491]	Time  0.483 ( 1.554)	Loss 3.3351e-01 (3.2695e-01)
Epoch: [5][3450/3491]	Time  0.483 ( 1.555)	Loss 3.5725e-01 (3.2700e-01)
Val: [0/4]	Time  4.245 ( 4.245)	Loss 2.8428e-01 (2.8428e-01)
Epoch 0005: val_loss did not improve from 0.33646 
Epoch: [6][   0/3491]	Time 12.690 (12.690)	Loss 3.1110e-01 (3.1110e-01)
Epoch: [6][  50/3491]	Time  0.483 ( 1.557)	Loss 3.4991e-01 (3.2841e-01)
Epoch: [6][ 100/3491]	Time  0.483 ( 1.445)	Loss 3.1161e-01 (3.2725e-01)
Epoch: [6][ 150/3491]	Time  0.483 ( 1.408)	Loss 3.2095e-01 (3.2584e-01)
Epoch: [6][ 200/3491]	Time  7.008 ( 1.431)	Loss 3.5220e-01 (3.2542e-01)
Epoch: [6][ 250/3491]	Time  0.953 ( 1.415)	Loss 3.1893e-01 (3.2511e-01)
Epoch: [6][ 300/3491]	Time  0.483 ( 1.405)	Loss 3.2940e-01 (3.2508e-01)
Epoch: [6][ 350/3491]	Time  0.772 ( 1.408)	Loss 3.0702e-01 (3.2548e-01)
Epoch: [6][ 400/3491]	Time  6.337 ( 1.422)	Loss 3.5716e-01 (3.2581e-01)
Epoch: [6][ 450/3491]	Time  1.820 ( 1.418)	Loss 2.9571e-01 (3.2594e-01)
Epoch: [6][ 500/3491]	Time  0.483 ( 1.425)	Loss 3.1349e-01 (3.2619e-01)
Epoch: [6][ 550/3491]	Time  4.668 ( 1.432)	Loss 3.3453e-01 (3.2640e-01)
Epoch: [6][ 600/3491]	Time  0.483 ( 1.436)	Loss 3.5231e-01 (3.2632e-01)
Epoch: [6][ 650/3491]	Time  0.483 ( 1.434)	Loss 3.1762e-01 (3.2625e-01)
Epoch: [6][ 700/3491]	Time  0.483 ( 1.438)	Loss 3.0992e-01 (3.2630e-01)
Epoch: [6][ 750/3491]	Time  4.886 ( 1.449)	Loss 3.2538e-01 (3.2635e-01)
Epoch: [6][ 800/3491]	Time  4.863 ( 1.453)	Loss 3.1390e-01 (3.2611e-01)
Epoch: [6][ 850/3491]	Time  0.483 ( 1.452)	Loss 3.1186e-01 (3.2614e-01)
Epoch: [6][ 900/3491]	Time  0.483 ( 1.455)	Loss 3.0248e-01 (3.2622e-01)
Epoch: [6][ 950/3491]	Time  3.660 ( 1.462)	Loss 3.4151e-01 (3.2638e-01)
Epoch: [6][1000/3491]	Time  1.282 ( 1.464)	Loss 3.1572e-01 (3.2613e-01)
Epoch: [6][1050/3491]	Time  0.483 ( 1.465)	Loss 3.3450e-01 (3.2647e-01)
Epoch: [6][1100/3491]	Time  0.483 ( 1.465)	Loss 3.4916e-01 (3.2652e-01)
Epoch: [6][1150/3491]	Time  1.700 ( 1.471)	Loss 3.2048e-01 (3.2641e-01)
Epoch: [6][1200/3491]	Time  2.983 ( 1.473)	Loss 3.6090e-01 (3.2646e-01)
Epoch: [6][1250/3491]	Time  0.483 ( 1.480)	Loss 3.2595e-01 (3.2658e-01)
Epoch: [6][1300/3491]	Time  0.483 ( 1.484)	Loss 3.5042e-01 (3.2661e-01)
Epoch: [6][1350/3491]	Time  0.483 ( 1.490)	Loss 3.1522e-01 (3.2640e-01)
Epoch: [6][1400/3491]	Time  2.760 ( 1.493)	Loss 3.4743e-01 (3.2650e-01)
Epoch: [6][1450/3491]	Time  0.483 ( 1.494)	Loss 3.0672e-01 (3.2644e-01)
Epoch: [6][1500/3491]	Time  0.483 ( 1.496)	Loss 3.2414e-01 (3.2653e-01)
Epoch: [6][1550/3491]	Time  0.483 ( 1.504)	Loss 3.1590e-01 (3.2662e-01)
Epoch: [6][1600/3491]	Time  7.520 ( 1.511)	Loss 3.0425e-01 (3.2668e-01)
Epoch: [6][1650/3491]	Time  0.483 ( 1.512)	Loss 3.6087e-01 (3.2672e-01)
Epoch: [6][1700/3491]	Time  0.483 ( 1.516)	Loss 3.2282e-01 (3.2680e-01)
Epoch: [6][1750/3491]	Time  0.483 ( 1.517)	Loss 3.1692e-01 (3.2671e-01)
Epoch: [6][1800/3491]	Time  8.114 ( 1.522)	Loss 3.3278e-01 (3.2673e-01)
Epoch: [6][1850/3491]	Time  0.483 ( 1.521)	Loss 3.4415e-01 (3.2678e-01)
Epoch: [6][1900/3491]	Time  0.483 ( 1.522)	Loss 3.1655e-01 (3.2673e-01)
Epoch: [6][1950/3491]	Time  0.484 ( 1.525)	Loss 3.4235e-01 (3.2680e-01)
Epoch: [6][2000/3491]	Time  3.855 ( 1.528)	Loss 3.2122e-01 (3.2671e-01)
Epoch: [6][2050/3491]	Time  0.483 ( 1.531)	Loss 2.9197e-01 (3.2674e-01)
Epoch: [6][2100/3491]	Time  0.483 ( 1.532)	Loss 3.5007e-01 (3.2675e-01)
Epoch: [6][2150/3491]	Time  0.483 ( 1.534)	Loss 3.6318e-01 (3.2674e-01)
Epoch: [6][2200/3491]	Time  7.314 ( 1.539)	Loss 3.5358e-01 (3.2674e-01)
Epoch: [6][2250/3491]	Time  0.483 ( 1.538)	Loss 3.0585e-01 (3.2677e-01)
Epoch: [6][2300/3491]	Time  0.484 ( 1.538)	Loss 3.2914e-01 (3.2686e-01)
Epoch: [6][2350/3491]	Time  0.484 ( 1.540)	Loss 3.1703e-01 (3.2681e-01)
Epoch: [6][2400/3491]	Time  3.061 ( 1.542)	Loss 3.7162e-01 (3.2688e-01)
Epoch: [6][2450/3491]	Time  0.483 ( 1.544)	Loss 3.3254e-01 (3.2686e-01)
Epoch: [6][2500/3491]	Time  0.483 ( 1.544)	Loss 3.1495e-01 (3.2687e-01)
Epoch: [6][2550/3491]	Time  0.483 ( 1.546)	Loss 3.4720e-01 (3.2688e-01)
Epoch: [6][2600/3491]	Time  4.149 ( 1.548)	Loss 3.0125e-01 (3.2689e-01)
Epoch: [6][2650/3491]	Time  0.483 ( 1.549)	Loss 3.4768e-01 (3.2694e-01)
Epoch: [6][2700/3491]	Time  0.483 ( 1.550)	Loss 3.1937e-01 (3.2697e-01)
Epoch: [6][2750/3491]	Time  0.484 ( 1.556)	Loss 3.3841e-01 (3.2698e-01)
Epoch: [6][2800/3491]	Time  0.483 ( 1.558)	Loss 3.3239e-01 (3.2691e-01)
Epoch: [6][2850/3491]	Time  0.483 ( 1.558)	Loss 3.0857e-01 (3.2684e-01)
Epoch: [6][2900/3491]	Time  0.483 ( 1.560)	Loss 3.3362e-01 (3.2682e-01)
Epoch: [6][2950/3491]	Time  0.483 ( 1.564)	Loss 3.3505e-01 (3.2687e-01)
Epoch: [6][3000/3491]	Time  0.483 ( 1.566)	Loss 3.3392e-01 (3.2685e-01)
Epoch: [6][3050/3491]	Time  0.483 ( 1.567)	Loss 3.3741e-01 (3.2685e-01)
Epoch: [6][3100/3491]	Time  0.483 ( 1.569)	Loss 3.0921e-01 (3.2686e-01)
Epoch: [6][3150/3491]	Time  0.484 ( 1.573)	Loss 3.3113e-01 (3.2687e-01)
Epoch: [6][3200/3491]	Time  0.483 ( 1.574)	Loss 3.2914e-01 (3.2682e-01)
Epoch: [6][3250/3491]	Time  0.483 ( 1.576)	Loss 3.3903e-01 (3.2681e-01)
Epoch: [6][3300/3491]	Time  0.484 ( 1.578)	Loss 2.9922e-01 (3.2683e-01)
Epoch: [6][3350/3491]	Time  0.483 ( 1.584)	Loss 2.9804e-01 (3.2680e-01)
Epoch: [6][3400/3491]	Time  0.597 ( 1.589)	Loss 3.3509e-01 (3.2680e-01)
Epoch: [6][3450/3491]	Time  0.483 ( 1.593)	Loss 3.0355e-01 (3.2681e-01)
Val: [0/4]	Time 14.963 (14.963)	Loss 2.8102e-01 (2.8102e-01)
Epoch 0006: val_loss did not improve from 0.33646 
Epoch: [7][   0/3491]	Time 15.076 (15.076)	Loss 3.1904e-01 (3.1904e-01)
Epoch: [7][  50/3491]	Time  0.483 ( 2.069)	Loss 3.5394e-01 (3.2686e-01)
Epoch: [7][ 100/3491]	Time  0.483 ( 1.941)	Loss 3.2396e-01 (3.2636e-01)
Epoch: [7][ 150/3491]	Time  0.483 ( 1.873)	Loss 3.2176e-01 (3.2649e-01)
Epoch: [7][ 200/3491]	Time 10.855 ( 1.893)	Loss 3.4159e-01 (3.2682e-01)
Epoch: [7][ 250/3491]	Time  2.164 ( 1.891)	Loss 3.3700e-01 (3.2716e-01)
Epoch: [7][ 300/3491]	Time  0.483 ( 1.878)	Loss 3.3291e-01 (3.2680e-01)
Epoch: [7][ 350/3491]	Time  0.483 ( 1.859)	Loss 2.9942e-01 (3.2667e-01)
Epoch: [7][ 400/3491]	Time 11.011 ( 1.871)	Loss 3.0825e-01 (3.2624e-01)
Epoch: [7][ 450/3491]	Time  6.160 ( 1.870)	Loss 3.3455e-01 (3.2709e-01)
Epoch: [7][ 500/3491]	Time  0.483 ( 1.861)	Loss 3.5420e-01 (3.2661e-01)
Epoch: [7][ 550/3491]	Time  0.483 ( 1.856)	Loss 3.1995e-01 (3.2645e-01)
Epoch: [7][ 600/3491]	Time 12.104 ( 1.870)	Loss 3.3102e-01 (3.2638e-01)
Epoch: [7][ 650/3491]	Time  0.483 ( 1.866)	Loss 3.2224e-01 (3.2603e-01)
Epoch: [7][ 700/3491]	Time  0.483 ( 1.865)	Loss 3.3016e-01 (3.2576e-01)
Epoch: [7][ 750/3491]	Time  4.950 ( 1.865)	Loss 3.1870e-01 (3.2592e-01)
Epoch: [7][ 800/3491]	Time  5.427 ( 1.859)	Loss 3.3895e-01 (3.2589e-01)
Epoch: [7][ 850/3491]	Time  0.483 ( 1.859)	Loss 3.6441e-01 (3.2616e-01)
Epoch: [7][ 900/3491]	Time  0.484 ( 1.849)	Loss 3.2061e-01 (3.2615e-01)
Epoch: [7][ 950/3491]	Time  4.689 ( 1.843)	Loss 3.1024e-01 (3.2618e-01)
Epoch: [7][1000/3491]	Time  2.080 ( 1.834)	Loss 3.3563e-01 (3.2615e-01)
Epoch: [7][1050/3491]	Time  0.484 ( 1.829)	Loss 3.2429e-01 (3.2630e-01)
Epoch: [7][1100/3491]	Time  0.483 ( 1.822)	Loss 2.8252e-01 (3.2643e-01)
Epoch: [7][1150/3491]	Time  1.839 ( 1.815)	Loss 3.4006e-01 (3.2640e-01)
Epoch: [7][1200/3491]	Time  0.483 ( 1.805)	Loss 3.4084e-01 (3.2631e-01)
Epoch: [7][1250/3491]	Time  0.483 ( 1.799)	Loss 3.1573e-01 (3.2616e-01)
Epoch: [7][1300/3491]	Time  0.483 ( 1.789)	Loss 3.1518e-01 (3.2616e-01)
Epoch: [7][1350/3491]	Time  9.567 ( 1.794)	Loss 3.4515e-01 (3.2614e-01)
Epoch: [7][1400/3491]	Time  0.483 ( 1.786)	Loss 3.4699e-01 (3.2623e-01)
Epoch: [7][1450/3491]	Time  0.483 ( 1.777)	Loss 3.1039e-01 (3.2617e-01)
Epoch: [7][1500/3491]	Time  0.483 ( 1.769)	Loss 3.3597e-01 (3.2623e-01)
Epoch: [7][1550/3491]	Time  9.263 ( 1.769)	Loss 3.3952e-01 (3.2630e-01)
Epoch: [7][1600/3491]	Time  0.483 ( 1.763)	Loss 3.0231e-01 (3.2632e-01)
Epoch: [7][1650/3491]	Time  0.483 ( 1.760)	Loss 3.2426e-01 (3.2636e-01)
Epoch: [7][1700/3491]	Time  0.484 ( 1.754)	Loss 3.4746e-01 (3.2646e-01)
Epoch: [7][1750/3491]	Time  8.717 ( 1.755)	Loss 3.4582e-01 (3.2640e-01)
Epoch: [7][1800/3491]	Time  0.483 ( 1.748)	Loss 3.1172e-01 (3.2637e-01)
Epoch: [7][1850/3491]	Time  0.483 ( 1.741)	Loss 3.3675e-01 (3.2636e-01)
Epoch: [7][1900/3491]	Time  0.483 ( 1.737)	Loss 3.1818e-01 (3.2639e-01)
Epoch: [7][1950/3491]	Time  6.337 ( 1.738)	Loss 3.4740e-01 (3.2633e-01)
Epoch: [7][2000/3491]	Time  0.483 ( 1.736)	Loss 3.2467e-01 (3.2637e-01)
Epoch: [7][2050/3491]	Time  0.483 ( 1.735)	Loss 3.1426e-01 (3.2636e-01)
Epoch: [7][2100/3491]	Time  0.483 ( 1.731)	Loss 3.2210e-01 (3.2622e-01)
Epoch: [7][2150/3491]	Time  9.310 ( 1.735)	Loss 3.1359e-01 (3.2618e-01)
Epoch: [7][2200/3491]	Time  0.483 ( 1.737)	Loss 3.0459e-01 (3.2614e-01)
Epoch: [7][2250/3491]	Time  0.483 ( 1.734)	Loss 2.9710e-01 (3.2610e-01)
Epoch: [7][2300/3491]	Time  0.483 ( 1.730)	Loss 3.2053e-01 (3.2616e-01)
Epoch: [7][2350/3491]	Time 10.104 ( 1.734)	Loss 3.4378e-01 (3.2620e-01)
Epoch: [7][2400/3491]	Time  0.483 ( 1.731)	Loss 3.5029e-01 (3.2615e-01)
Epoch: [7][2450/3491]	Time  0.483 ( 1.730)	Loss 3.1330e-01 (3.2616e-01)
Epoch: [7][2500/3491]	Time  0.483 ( 1.727)	Loss 3.3245e-01 (3.2614e-01)
Epoch: [7][2550/3491]	Time  8.990 ( 1.727)	Loss 3.2053e-01 (3.2609e-01)
Epoch: [7][2600/3491]	Time  0.483 ( 1.725)	Loss 3.2149e-01 (3.2605e-01)
Epoch: [7][2650/3491]	Time  0.483 ( 1.723)	Loss 3.2544e-01 (3.2605e-01)
Epoch: [7][2700/3491]	Time  0.483 ( 1.723)	Loss 2.9727e-01 (3.2598e-01)
Epoch: [7][2750/3491]	Time 10.693 ( 1.727)	Loss 3.0274e-01 (3.2595e-01)
Epoch: [7][2800/3491]	Time  0.483 ( 1.725)	Loss 3.1753e-01 (3.2589e-01)
Epoch: [7][2850/3491]	Time  0.483 ( 1.722)	Loss 3.3607e-01 (3.2588e-01)
Epoch: [7][2900/3491]	Time  0.483 ( 1.721)	Loss 3.1288e-01 (3.2596e-01)
Epoch: [7][2950/3491]	Time  9.954 ( 1.725)	Loss 3.3997e-01 (3.2594e-01)
Epoch: [7][3000/3491]	Time  0.483 ( 1.725)	Loss 2.9722e-01 (3.2589e-01)
Epoch: [7][3050/3491]	Time  0.483 ( 1.728)	Loss 3.1622e-01 (3.2592e-01)
Epoch: [7][3100/3491]	Time  0.483 ( 1.729)	Loss 3.2115e-01 (3.2599e-01)
Epoch: [7][3150/3491]	Time 10.683 ( 1.731)	Loss 3.2300e-01 (3.2601e-01)
Epoch: [7][3200/3491]	Time  0.483 ( 1.731)	Loss 3.4920e-01 (3.2602e-01)
Epoch: [7][3250/3491]	Time  0.483 ( 1.733)	Loss 3.3964e-01 (3.2601e-01)
Epoch: [7][3300/3491]	Time  0.483 ( 1.733)	Loss 3.3817e-01 (3.2598e-01)
Epoch: [7][3350/3491]	Time  9.895 ( 1.736)	Loss 3.2822e-01 (3.2599e-01)
Epoch: [7][3400/3491]	Time  0.483 ( 1.736)	Loss 3.1392e-01 (3.2596e-01)
Epoch: [7][3450/3491]	Time  0.483 ( 1.734)	Loss 3.5155e-01 (3.2598e-01)
Val: [0/4]	Time 13.543 (13.543)	Loss 2.7823e-01 (2.7823e-01)
Epoch 0007: val_loss did not improve from 0.33646 
Epoch: [8][   0/3491]	Time 12.631 (12.631)	Loss 3.2631e-01 (3.2631e-01)
Epoch: [8][  50/3491]	Time  0.483 ( 1.846)	Loss 3.1829e-01 (3.2278e-01)
Epoch: [8][ 100/3491]	Time  0.483 ( 1.725)	Loss 3.2096e-01 (3.2203e-01)
Epoch: [8][ 150/3491]	Time  0.483 ( 1.708)	Loss 3.2944e-01 (3.2248e-01)
Epoch: [8][ 200/3491]	Time  3.322 ( 1.728)	Loss 3.2781e-01 (3.2410e-01)
Epoch: [8][ 250/3491]	Time  0.483 ( 1.755)	Loss 3.4003e-01 (3.2381e-01)
Epoch: [8][ 300/3491]	Time  1.868 ( 1.748)	Loss 3.4066e-01 (3.2372e-01)
Epoch: [8][ 350/3491]	Time  1.035 ( 1.753)	Loss 3.1896e-01 (3.2326e-01)
Epoch: [8][ 400/3491]	Time  7.013 ( 1.773)	Loss 3.2590e-01 (3.2399e-01)
Epoch: [8][ 450/3491]	Time  0.483 ( 1.793)	Loss 3.1136e-01 (3.2417e-01)
Epoch: [8][ 500/3491]	Time  0.483 ( 1.810)	Loss 3.0975e-01 (3.2455e-01)
Epoch: [8][ 550/3491]	Time  2.324 ( 1.827)	Loss 3.1318e-01 (3.2469e-01)
Epoch: [8][ 600/3491]	Time 10.976 ( 1.866)	Loss 3.1208e-01 (3.2468e-01)
Epoch: [8][ 650/3491]	Time  0.483 ( 1.881)	Loss 3.5158e-01 (3.2484e-01)
Epoch: [8][ 700/3491]	Time  2.108 ( 1.898)	Loss 3.2855e-01 (3.2497e-01)
Epoch: [8][ 750/3491]	Time  0.483 ( 1.913)	Loss 3.4246e-01 (3.2486e-01)
Epoch: [8][ 800/3491]	Time 10.612 ( 1.939)	Loss 2.9192e-01 (3.2518e-01)
Epoch: [8][ 850/3491]	Time  0.483 ( 1.943)	Loss 3.3320e-01 (3.2505e-01)
Epoch: [8][ 900/3491]	Time  0.484 ( 1.946)	Loss 3.4218e-01 (3.2510e-01)
Epoch: [8][ 950/3491]	Time  0.483 ( 1.953)	Loss 3.1870e-01 (3.2499e-01)
Epoch: [8][1000/3491]	Time  4.481 ( 1.961)	Loss 3.0397e-01 (3.2511e-01)
Epoch: [8][1050/3491]	Time  0.483 ( 1.977)	Loss 3.3331e-01 (3.2515e-01)
Epoch: [8][1100/3491]	Time  0.483 ( 1.977)	Loss 2.8150e-01 (3.2504e-01)
Epoch: [8][1150/3491]	Time  0.483 ( 1.979)	Loss 2.9972e-01 (3.2514e-01)
Epoch: [8][1200/3491]	Time  0.483 ( 1.983)	Loss 3.0317e-01 (3.2514e-01)
Epoch: [8][1250/3491]	Time  0.483 ( 1.997)	Loss 3.0273e-01 (3.2511e-01)
Epoch: [8][1300/3491]	Time  0.483 ( 2.002)	Loss 3.1220e-01 (3.2513e-01)
Epoch: [8][1350/3491]	Time  0.483 ( 2.005)	Loss 3.2785e-01 (3.2521e-01)
Epoch: [8][1400/3491]	Time  0.483 ( 2.006)	Loss 3.6529e-01 (3.2516e-01)
Epoch: [8][1450/3491]	Time  0.483 ( 2.015)	Loss 3.2898e-01 (3.2521e-01)
Epoch: [8][1500/3491]	Time  0.483 ( 2.013)	Loss 3.6405e-01 (3.2529e-01)
Epoch: [8][1550/3491]	Time  0.483 ( 2.005)	Loss 2.9576e-01 (3.2526e-01)
Epoch: [8][1600/3491]	Time  0.483 ( 1.997)	Loss 3.2829e-01 (3.2540e-01)
Epoch: [8][1650/3491]	Time  0.483 ( 1.993)	Loss 3.2440e-01 (3.2544e-01)
Epoch: [8][1700/3491]	Time  0.483 ( 1.985)	Loss 3.4530e-01 (3.2535e-01)
Epoch: [8][1750/3491]	Time  0.484 ( 1.975)	Loss 3.0935e-01 (3.2535e-01)
Epoch: [8][1800/3491]	Time  0.483 ( 1.967)	Loss 3.2897e-01 (3.2544e-01)
Epoch: [8][1850/3491]	Time  0.484 ( 1.962)	Loss 3.2785e-01 (3.2530e-01)
Epoch: [8][1900/3491]	Time  0.483 ( 1.952)	Loss 3.1860e-01 (3.2530e-01)
Epoch: [8][1950/3491]	Time  0.483 ( 1.945)	Loss 3.4384e-01 (3.2521e-01)
Epoch: [8][2000/3491]	Time  0.483 ( 1.938)	Loss 3.2811e-01 (3.2520e-01)
Epoch: [8][2050/3491]	Time  0.483 ( 1.936)	Loss 3.0325e-01 (3.2510e-01)
Epoch: [8][2100/3491]	Time  0.483 ( 1.928)	Loss 3.2068e-01 (3.2504e-01)
Epoch: [8][2150/3491]	Time  0.483 ( 1.921)	Loss 3.0558e-01 (3.2507e-01)
Epoch: [8][2200/3491]	Time  0.483 ( 1.915)	Loss 3.1744e-01 (3.2497e-01)
Epoch: [8][2250/3491]	Time  1.863 ( 1.913)	Loss 3.3646e-01 (3.2504e-01)
Epoch: [8][2300/3491]	Time  0.483 ( 1.907)	Loss 3.2173e-01 (3.2521e-01)
Epoch: [8][2350/3491]	Time  0.484 ( 1.902)	Loss 3.1944e-01 (3.2522e-01)
Epoch: [8][2400/3491]	Time  0.483 ( 1.899)	Loss 3.5761e-01 (3.2521e-01)
Epoch: [8][2450/3491]	Time  7.685 ( 1.898)	Loss 3.4259e-01 (3.2509e-01)
Epoch: [8][2500/3491]	Time  0.484 ( 1.893)	Loss 3.2230e-01 (3.2515e-01)
Epoch: [8][2550/3491]	Time  0.484 ( 1.889)	Loss 3.3091e-01 (3.2512e-01)
Epoch: [8][2600/3491]	Time  0.483 ( 1.888)	Loss 3.0981e-01 (3.2506e-01)
Epoch: [8][2650/3491]	Time 11.964 ( 1.888)	Loss 3.3717e-01 (3.2503e-01)
Epoch: [8][2700/3491]	Time  0.483 ( 1.886)	Loss 3.2698e-01 (3.2507e-01)
Epoch: [8][2750/3491]	Time  0.483 ( 1.882)	Loss 3.1805e-01 (3.2503e-01)
Epoch: [8][2800/3491]	Time  0.483 ( 1.878)	Loss 3.3745e-01 (3.2502e-01)
Epoch: [8][2850/3491]	Time  9.198 ( 1.876)	Loss 3.3857e-01 (3.2503e-01)
Epoch: [8][2900/3491]	Time  0.483 ( 1.870)	Loss 3.3436e-01 (3.2509e-01)
Epoch: [8][2950/3491]	Time  0.483 ( 1.865)	Loss 3.2415e-01 (3.2505e-01)
Epoch: [8][3000/3491]	Time  0.483 ( 1.860)	Loss 3.0651e-01 (3.2503e-01)
Epoch: [8][3050/3491]	Time  8.926 ( 1.857)	Loss 3.3043e-01 (3.2504e-01)
Epoch: [8][3100/3491]	Time  0.483 ( 1.852)	Loss 3.4546e-01 (3.2507e-01)
Epoch: [8][3150/3491]	Time  0.483 ( 1.847)	Loss 2.8996e-01 (3.2511e-01)
Epoch: [8][3200/3491]	Time  0.483 ( 1.844)	Loss 3.5690e-01 (3.2510e-01)
Epoch: [8][3250/3491]	Time 14.428 ( 1.851)	Loss 3.2898e-01 (3.2512e-01)
Epoch: [8][3300/3491]	Time  0.483 ( 1.852)	Loss 3.3745e-01 (3.2518e-01)
Epoch: [8][3350/3491]	Time  0.483 ( 1.855)	Loss 3.1499e-01 (3.2509e-01)
Epoch: [8][3400/3491]	Time  0.483 ( 1.860)	Loss 3.1430e-01 (3.2510e-01)
Epoch: [8][3450/3491]	Time 11.818 ( 1.866)	Loss 3.0019e-01 (3.2511e-01)
Val: [0/4]	Time 14.192 (14.192)	Loss 2.8496e-01 (2.8496e-01)
Epoch 0008: val_loss did not improve from 0.33646 
Epoch: [9][   0/3491]	Time 16.314 (16.314)	Loss 2.9396e-01 (2.9396e-01)
Epoch: [9][  50/3491]	Time  0.483 ( 2.100)	Loss 3.1735e-01 (3.2426e-01)
Epoch: [9][ 100/3491]	Time  0.483 ( 1.935)	Loss 3.2252e-01 (3.2474e-01)
Epoch: [9][ 150/3491]	Time  0.483 ( 1.874)	Loss 3.3240e-01 (3.2375e-01)
Epoch: [9][ 200/3491]	Time  8.591 ( 1.852)	Loss 3.5628e-01 (3.2342e-01)
Epoch: [9][ 250/3491]	Time  0.483 ( 1.790)	Loss 3.4244e-01 (3.2321e-01)
Epoch: [9][ 300/3491]	Time  0.483 ( 1.740)	Loss 3.2677e-01 (3.2303e-01)
Epoch: [9][ 350/3491]	Time  0.483 ( 1.728)	Loss 3.2175e-01 (3.2285e-01)
Epoch: [9][ 400/3491]	Time 12.321 ( 1.757)	Loss 3.1267e-01 (3.2307e-01)
Epoch: [9][ 450/3491]	Time  0.483 ( 1.758)	Loss 3.1402e-01 (3.2328e-01)
Epoch: [9][ 500/3491]	Time  0.483 ( 1.766)	Loss 3.0913e-01 (3.2373e-01)
Epoch: [9][ 550/3491]	Time  0.483 ( 1.769)	Loss 3.2498e-01 (3.2378e-01)
Epoch: [9][ 600/3491]	Time 10.420 ( 1.795)	Loss 3.0564e-01 (3.2393e-01)
Epoch: [9][ 650/3491]	Time  0.483 ( 1.794)	Loss 3.1426e-01 (3.2406e-01)
Epoch: [9][ 700/3491]	Time  0.483 ( 1.784)	Loss 3.3592e-01 (3.2404e-01)
Epoch: [9][ 750/3491]	Time  0.483 ( 1.773)	Loss 3.2378e-01 (3.2397e-01)
Epoch: [9][ 800/3491]	Time  8.901 ( 1.773)	Loss 3.3229e-01 (3.2397e-01)
Epoch: [9][ 850/3491]	Time  0.483 ( 1.760)	Loss 3.1853e-01 (3.2410e-01)
Epoch: [9][ 900/3491]	Time  0.483 ( 1.752)	Loss 3.4191e-01 (3.2412e-01)
Epoch: [9][ 950/3491]	Time  0.483 ( 1.746)	Loss 3.0609e-01 (3.2423e-01)
Epoch: [9][1000/3491]	Time  9.747 ( 1.746)	Loss 2.8244e-01 (3.2383e-01)
Epoch: [9][1050/3491]	Time  0.483 ( 1.740)	Loss 3.4650e-01 (3.2414e-01)
Epoch: [9][1100/3491]	Time  0.483 ( 1.735)	Loss 3.4823e-01 (3.2404e-01)
Epoch: [9][1150/3491]	Time  0.483 ( 1.733)	Loss 3.0525e-01 (3.2396e-01)
Epoch: [9][1200/3491]	Time  8.187 ( 1.736)	Loss 3.0725e-01 (3.2404e-01)
Epoch: [9][1250/3491]	Time  0.483 ( 1.736)	Loss 2.9299e-01 (3.2424e-01)
Epoch: [9][1300/3491]	Time  0.483 ( 1.735)	Loss 3.4582e-01 (3.2415e-01)
Epoch: [9][1350/3491]	Time  0.483 ( 1.734)	Loss 3.4464e-01 (3.2411e-01)
Epoch: [9][1400/3491]	Time  6.056 ( 1.735)	Loss 3.1881e-01 (3.2404e-01)
Epoch: [9][1450/3491]	Time  2.930 ( 1.733)	Loss 2.9397e-01 (3.2403e-01)
Epoch: [9][1500/3491]	Time  0.483 ( 1.730)	Loss 3.3042e-01 (3.2408e-01)
Epoch: [9][1550/3491]	Time  0.483 ( 1.729)	Loss 3.1463e-01 (3.2423e-01)
Epoch: [9][1600/3491]	Time  1.304 ( 1.733)	Loss 3.2950e-01 (3.2413e-01)
Epoch: [9][1650/3491]	Time 11.999 ( 1.745)	Loss 3.2917e-01 (3.2424e-01)
Epoch: [9][1700/3491]	Time  0.483 ( 1.749)	Loss 3.2267e-01 (3.2426e-01)
Epoch: [9][1750/3491]	Time  0.483 ( 1.751)	Loss 3.4312e-01 (3.2433e-01)
Epoch: [9][1800/3491]	Time  0.483 ( 1.755)	Loss 3.0604e-01 (3.2432e-01)
Epoch: [9][1850/3491]	Time 13.275 ( 1.765)	Loss 2.9463e-01 (3.2425e-01)
Epoch: [9][1900/3491]	Time  0.483 ( 1.769)	Loss 3.5891e-01 (3.2428e-01)
Epoch: [9][1950/3491]	Time  0.483 ( 1.771)	Loss 3.1765e-01 (3.2435e-01)
Epoch: [9][2000/3491]	Time  7.191 ( 1.778)	Loss 3.0559e-01 (3.2429e-01)
Epoch: [9][2050/3491]	Time  6.822 ( 1.782)	Loss 3.0830e-01 (3.2432e-01)
Epoch: [9][2100/3491]	Time  0.483 ( 1.785)	Loss 3.2214e-01 (3.2434e-01)
Epoch: [9][2150/3491]	Time  0.483 ( 1.789)	Loss 3.4608e-01 (3.2440e-01)
Epoch: [9][2200/3491]	Time 12.851 ( 1.800)	Loss 2.9841e-01 (3.2431e-01)
Epoch: [9][2250/3491]	Time  8.807 ( 1.808)	Loss 3.1841e-01 (3.2429e-01)
Epoch: [9][2300/3491]	Time  0.483 ( 1.811)	Loss 3.1024e-01 (3.2435e-01)
Epoch: [9][2350/3491]	Time  0.483 ( 1.816)	Loss 3.1397e-01 (3.2436e-01)
Epoch: [9][2400/3491]	Time  8.882 ( 1.821)	Loss 3.1895e-01 (3.2442e-01)
Epoch: [9][2450/3491]	Time  5.446 ( 1.824)	Loss 3.1109e-01 (3.2441e-01)
Epoch: [9][2500/3491]	Time  0.483 ( 1.824)	Loss 3.0732e-01 (3.2447e-01)
Epoch: [9][2550/3491]	Time  0.483 ( 1.823)	Loss 3.2346e-01 (3.2453e-01)
Epoch: [9][2600/3491]	Time 12.170 ( 1.828)	Loss 3.1987e-01 (3.2456e-01)
Epoch: [9][2650/3491]	Time  0.483 ( 1.826)	Loss 3.1890e-01 (3.2457e-01)
Epoch: [9][2700/3491]	Time  0.483 ( 1.825)	Loss 3.2052e-01 (3.2454e-01)
Epoch: [9][2750/3491]	Time  0.483 ( 1.823)	Loss 3.1836e-01 (3.2449e-01)
Epoch: [9][2800/3491]	Time  4.383 ( 1.824)	Loss 3.1253e-01 (3.2451e-01)
Epoch: [9][2850/3491]	Time  7.617 ( 1.824)	Loss 2.9504e-01 (3.2455e-01)
Epoch: [9][2900/3491]	Time  0.483 ( 1.821)	Loss 3.4392e-01 (3.2454e-01)
Epoch: [9][2950/3491]	Time  0.483 ( 1.821)	Loss 3.5380e-01 (3.2458e-01)
Epoch: [9][3000/3491]	Time  0.483 ( 1.818)	Loss 3.5169e-01 (3.2457e-01)
Epoch: [9][3050/3491]	Time  7.209 ( 1.816)	Loss 3.1822e-01 (3.2456e-01)
Epoch: [9][3100/3491]	Time  0.483 ( 1.811)	Loss 3.2996e-01 (3.2459e-01)
Epoch: [9][3150/3491]	Time  0.483 ( 1.806)	Loss 2.9333e-01 (3.2460e-01)
Epoch: [9][3200/3491]	Time  0.483 ( 1.802)	Loss 3.1078e-01 (3.2458e-01)
Epoch: [9][3250/3491]	Time  9.605 ( 1.800)	Loss 3.2800e-01 (3.2455e-01)
Epoch: [9][3300/3491]	Time  0.483 ( 1.796)	Loss 3.1962e-01 (3.2463e-01)
Epoch: [9][3350/3491]	Time  0.483 ( 1.791)	Loss 3.2440e-01 (3.2467e-01)
Epoch: [9][3400/3491]	Time  0.483 ( 1.788)	Loss 3.1561e-01 (3.2466e-01)
Epoch: [9][3450/3491]	Time 10.117 ( 1.789)	Loss 3.2515e-01 (3.2467e-01)
Val: [0/4]	Time 12.952 (12.952)	Loss 2.7911e-01 (2.7911e-01)
Epoch 0009: val_loss did not improve from 0.33646 
Epoch: [10][   0/3491]	Time 11.127 (11.127)	Loss 3.1926e-01 (3.1926e-01)
Epoch: [10][  50/3491]	Time  1.051 ( 1.672)	Loss 3.5459e-01 (3.2544e-01)
Epoch: [10][ 100/3491]	Time  0.483 ( 1.533)	Loss 3.0071e-01 (3.2291e-01)
Epoch: [10][ 150/3491]	Time  0.483 ( 1.489)	Loss 3.2530e-01 (3.2202e-01)
Epoch: [10][ 200/3491]	Time  4.830 ( 1.488)	Loss 3.3865e-01 (3.2334e-01)
Epoch: [10][ 250/3491]	Time  0.628 ( 1.468)	Loss 3.5044e-01 (3.2406e-01)
Epoch: [10][ 300/3491]	Time  2.956 ( 1.475)	Loss 3.5141e-01 (3.2378e-01)
Epoch: [10][ 350/3491]	Time  0.483 ( 1.468)	Loss 2.9508e-01 (3.2326e-01)
Epoch: [10][ 400/3491]	Time  3.590 ( 1.486)	Loss 3.3334e-01 (3.2362e-01)
Epoch: [10][ 450/3491]	Time  2.785 ( 1.493)	Loss 3.5771e-01 (3.2328e-01)
Epoch: [10][ 500/3491]	Time  2.137 ( 1.503)	Loss 3.0848e-01 (3.2348e-01)
Epoch: [10][ 550/3491]	Time  0.483 ( 1.500)	Loss 3.0643e-01 (3.2319e-01)
Epoch: [10][ 600/3491]	Time  3.792 ( 1.504)	Loss 3.3091e-01 (3.2323e-01)
Epoch: [10][ 650/3491]	Time  5.876 ( 1.517)	Loss 3.4249e-01 (3.2327e-01)
Epoch: [10][ 700/3491]	Time  0.483 ( 1.524)	Loss 3.0255e-01 (3.2328e-01)
Epoch: [10][ 750/3491]	Time  0.483 ( 1.537)	Loss 3.1019e-01 (3.2305e-01)
Epoch: [10][ 800/3491]	Time  0.483 ( 1.546)	Loss 3.2489e-01 (3.2322e-01)
Epoch: [10][ 850/3491]	Time  9.347 ( 1.566)	Loss 2.8668e-01 (3.2330e-01)
Epoch: [10][ 900/3491]	Time  0.484 ( 1.565)	Loss 3.1666e-01 (3.2345e-01)
Epoch: [10][ 950/3491]	Time  0.483 ( 1.564)	Loss 3.4154e-01 (3.2336e-01)
Epoch: [10][1000/3491]	Time  0.483 ( 1.561)	Loss 3.2768e-01 (3.2349e-01)
Epoch: [10][1050/3491]	Time  9.251 ( 1.567)	Loss 3.5474e-01 (3.2370e-01)
Epoch: [10][1100/3491]	Time  0.484 ( 1.566)	Loss 3.0908e-01 (3.2376e-01)
Epoch: [10][1150/3491]	Time  0.483 ( 1.566)	Loss 3.2139e-01 (3.2351e-01)
Epoch: [10][1200/3491]	Time  0.483 ( 1.572)	Loss 3.5803e-01 (3.2359e-01)
Epoch: [10][1250/3491]	Time  9.597 ( 1.582)	Loss 3.0807e-01 (3.2354e-01)
Epoch: [10][1300/3491]	Time  0.484 ( 1.583)	Loss 3.5426e-01 (3.2356e-01)
Epoch: [10][1350/3491]	Time  0.483 ( 1.583)	Loss 3.2061e-01 (3.2363e-01)
Epoch: [10][1400/3491]	Time  0.483 ( 1.582)	Loss 3.2124e-01 (3.2369e-01)
Epoch: [10][1450/3491]	Time 11.182 ( 1.595)	Loss 3.4699e-01 (3.2377e-01)
Epoch: [10][1500/3491]	Time  0.484 ( 1.594)	Loss 3.3022e-01 (3.2373e-01)
Epoch: [10][1550/3491]	Time  0.483 ( 1.594)	Loss 2.8573e-01 (3.2376e-01)
Epoch: [10][1600/3491]	Time  0.483 ( 1.594)	Loss 3.3993e-01 (3.2379e-01)
Epoch: [10][1650/3491]	Time  8.517 ( 1.597)	Loss 3.2565e-01 (3.2384e-01)
Epoch: [10][1700/3491]	Time  0.484 ( 1.598)	Loss 3.2326e-01 (3.2403e-01)
Epoch: [10][1750/3491]	Time  0.483 ( 1.599)	Loss 3.0807e-01 (3.2414e-01)
Epoch: [10][1800/3491]	Time  0.483 ( 1.599)	Loss 3.4129e-01 (3.2426e-01)
Epoch: [10][1850/3491]	Time 13.444 ( 1.606)	Loss 3.1942e-01 (3.2440e-01)
Epoch: [10][1900/3491]	Time  0.484 ( 1.608)	Loss 3.3844e-01 (3.2450e-01)
Epoch: [10][1950/3491]	Time  0.483 ( 1.609)	Loss 3.3177e-01 (3.2446e-01)
Epoch: [10][2000/3491]	Time  0.483 ( 1.610)	Loss 3.1207e-01 (3.2444e-01)
Epoch: [10][2050/3491]	Time  5.124 ( 1.613)	Loss 3.2125e-01 (3.2440e-01)
Epoch: [10][2100/3491]	Time  0.483 ( 1.616)	Loss 3.3061e-01 (3.2441e-01)
Epoch: [10][2150/3491]	Time  0.483 ( 1.622)	Loss 3.5640e-01 (3.2439e-01)
Epoch: [10][2200/3491]	Time  0.483 ( 1.623)	Loss 3.5173e-01 (3.2438e-01)
Epoch: [10][2250/3491]	Time  0.483 ( 1.623)	Loss 3.1187e-01 (3.2445e-01)
Epoch: [10][2300/3491]	Time  4.735 ( 1.626)	Loss 3.1739e-01 (3.2440e-01)
Epoch: [10][2350/3491]	Time  0.483 ( 1.629)	Loss 3.4995e-01 (3.2444e-01)
Epoch: [10][2400/3491]	Time  0.483 ( 1.632)	Loss 3.2761e-01 (3.2440e-01)
Epoch: [10][2450/3491]	Time  0.483 ( 1.633)	Loss 3.2511e-01 (3.2436e-01)
Epoch: [10][2500/3491]	Time  0.483 ( 1.632)	Loss 3.3412e-01 (3.2437e-01)
Epoch: [10][2550/3491]	Time  0.484 ( 1.637)	Loss 2.9746e-01 (3.2424e-01)
Epoch: [10][2600/3491]	Time  0.484 ( 1.635)	Loss 3.0657e-01 (3.2426e-01)
Epoch: [10][2650/3491]	Time  0.483 ( 1.632)	Loss 3.2618e-01 (3.2433e-01)
Epoch: [10][2700/3491]	Time  0.484 ( 1.630)	Loss 3.2930e-01 (3.2439e-01)
Epoch: [10][2750/3491]	Time  0.484 ( 1.630)	Loss 3.4559e-01 (3.2440e-01)
Epoch: [10][2800/3491]	Time  0.483 ( 1.629)	Loss 2.8055e-01 (3.2432e-01)
Epoch: [10][2850/3491]	Time  0.483 ( 1.626)	Loss 3.2911e-01 (3.2427e-01)
Epoch: [10][2900/3491]	Time  0.483 ( 1.624)	Loss 3.4566e-01 (3.2419e-01)
Epoch: [10][2950/3491]	Time  0.483 ( 1.625)	Loss 3.3118e-01 (3.2415e-01)
Epoch: [10][3000/3491]	Time  0.483 ( 1.624)	Loss 3.1302e-01 (3.2407e-01)
Epoch: [10][3050/3491]	Time  0.483 ( 1.622)	Loss 3.2901e-01 (3.2406e-01)
Epoch: [10][3100/3491]	Time  0.483 ( 1.620)	Loss 3.2553e-01 (3.2410e-01)
Epoch: [10][3150/3491]	Time  0.483 ( 1.621)	Loss 3.3515e-01 (3.2416e-01)
Epoch: [10][3200/3491]	Time  0.483 ( 1.620)	Loss 3.2249e-01 (3.2415e-01)
Epoch: [10][3250/3491]	Time  0.483 ( 1.619)	Loss 3.3936e-01 (3.2416e-01)
Epoch: [10][3300/3491]	Time  0.483 ( 1.617)	Loss 3.2429e-01 (3.2421e-01)
Epoch: [10][3350/3491]	Time  0.484 ( 1.618)	Loss 3.2863e-01 (3.2421e-01)
Epoch: [10][3400/3491]	Time  0.483 ( 1.617)	Loss 3.3878e-01 (3.2430e-01)
Epoch: [10][3450/3491]	Time  0.483 ( 1.615)	Loss 3.5311e-01 (3.2430e-01)
Val: [0/4]	Time 12.259 (12.259)	Loss 2.8445e-01 (2.8445e-01)
Epoch 0010: val_loss did not improve from 0.33646 
Epoch: [11][   0/3491]	Time 13.557 (13.557)	Loss 3.1417e-01 (3.1417e-01)
Epoch: [11][  50/3491]	Time  0.483 ( 1.575)	Loss 3.2187e-01 (3.2405e-01)
Epoch: [11][ 100/3491]	Time  0.483 ( 1.439)	Loss 3.3784e-01 (3.2277e-01)
Epoch: [11][ 150/3491]	Time  0.483 ( 1.423)	Loss 3.2412e-01 (3.2341e-01)
Epoch: [11][ 200/3491]	Time  8.119 ( 1.448)	Loss 3.2488e-01 (3.2307e-01)
Epoch: [11][ 250/3491]	Time  0.483 ( 1.443)	Loss 3.0422e-01 (3.2246e-01)
Epoch: [11][ 300/3491]	Time  0.483 ( 1.438)	Loss 2.9289e-01 (3.2241e-01)
Epoch: [11][ 350/3491]	Time  0.483 ( 1.453)	Loss 3.2350e-01 (3.2283e-01)
Epoch: [11][ 400/3491]	Time  4.660 ( 1.461)	Loss 3.3424e-01 (3.2323e-01)
Epoch: [11][ 450/3491]	Time  6.288 ( 1.470)	Loss 2.9222e-01 (3.2298e-01)
Epoch: [11][ 500/3491]	Time  0.483 ( 1.463)	Loss 3.6111e-01 (3.2287e-01)
Epoch: [11][ 550/3491]	Time  0.483 ( 1.460)	Loss 3.1068e-01 (3.2334e-01)
Epoch: [11][ 600/3491]	Time  1.706 ( 1.460)	Loss 2.9982e-01 (3.2325e-01)
Epoch: [11][ 650/3491]	Time  6.839 ( 1.470)	Loss 3.3527e-01 (3.2324e-01)
Epoch: [11][ 700/3491]	Time  0.483 ( 1.471)	Loss 2.9832e-01 (3.2327e-01)
Epoch: [11][ 750/3491]	Time  0.483 ( 1.475)	Loss 2.9297e-01 (3.2339e-01)
Epoch: [11][ 800/3491]	Time  0.483 ( 1.475)	Loss 3.0394e-01 (3.2352e-01)
Epoch: [11][ 850/3491]	Time  8.470 ( 1.485)	Loss 3.1701e-01 (3.2373e-01)
Epoch: [11][ 900/3491]	Time  0.483 ( 1.490)	Loss 3.3095e-01 (3.2364e-01)
Epoch: [11][ 950/3491]	Time  0.483 ( 1.496)	Loss 3.4329e-01 (3.2370e-01)
Epoch: [11][1000/3491]	Time  0.483 ( 1.498)	Loss 3.4963e-01 (3.2369e-01)
Epoch: [11][1050/3491]	Time  8.911 ( 1.513)	Loss 3.2742e-01 (3.2365e-01)
Epoch: [11][1100/3491]	Time  0.483 ( 1.521)	Loss 3.2228e-01 (3.2371e-01)
Epoch: [11][1150/3491]	Time  0.483 ( 1.529)	Loss 3.3394e-01 (3.2380e-01)
Epoch: [11][1200/3491]	Time  0.483 ( 1.534)	Loss 3.2947e-01 (3.2401e-01)
Epoch: [11][1250/3491]	Time  9.258 ( 1.543)	Loss 3.3548e-01 (3.2395e-01)
Epoch: [11][1300/3491]	Time  0.484 ( 1.542)	Loss 3.1981e-01 (3.2377e-01)
Epoch: [11][1350/3491]	Time  0.483 ( 1.541)	Loss 3.1518e-01 (3.2391e-01)
Epoch: [11][1400/3491]	Time  0.483 ( 1.538)	Loss 3.4068e-01 (3.2394e-01)
Epoch: [11][1450/3491]	Time  9.141 ( 1.543)	Loss 3.3479e-01 (3.2403e-01)
Epoch: [11][1500/3491]	Time  0.483 ( 1.542)	Loss 3.1309e-01 (3.2405e-01)
Epoch: [11][1550/3491]	Time  0.483 ( 1.542)	Loss 3.4110e-01 (3.2407e-01)
Epoch: [11][1600/3491]	Time  0.483 ( 1.542)	Loss 3.0272e-01 (3.2410e-01)
Epoch: [11][1650/3491]	Time  9.736 ( 1.546)	Loss 3.5080e-01 (3.2408e-01)
Epoch: [11][1700/3491]	Time  0.483 ( 1.544)	Loss 3.1937e-01 (3.2404e-01)
Epoch: [11][1750/3491]	Time  1.272 ( 1.543)	Loss 3.2420e-01 (3.2405e-01)
Epoch: [11][1800/3491]	Time  0.483 ( 1.543)	Loss 2.9154e-01 (3.2409e-01)
Epoch: [11][1850/3491]	Time  6.245 ( 1.549)	Loss 2.9589e-01 (3.2403e-01)
Epoch: [11][1900/3491]	Time  0.483 ( 1.556)	Loss 3.1304e-01 (3.2401e-01)
Epoch: [11][1950/3491]	Time  3.938 ( 1.562)	Loss 3.5898e-01 (3.2402e-01)
Epoch: [11][2000/3491]	Time  0.483 ( 1.563)	Loss 2.9663e-01 (3.2400e-01)
Epoch: [11][2050/3491]	Time  7.955 ( 1.567)	Loss 3.1121e-01 (3.2396e-01)
Epoch: [11][2100/3491]	Time  0.482 ( 1.567)	Loss 3.1598e-01 (3.2399e-01)
Epoch: [11][2150/3491]	Time  4.620 ( 1.570)	Loss 3.1605e-01 (3.2399e-01)
Epoch: [11][2200/3491]	Time  0.483 ( 1.573)	Loss 2.7135e-01 (3.2393e-01)
Epoch: [11][2250/3491]	Time  3.028 ( 1.575)	Loss 3.2103e-01 (3.2387e-01)
Epoch: [11][2300/3491]	Time  0.483 ( 1.576)	Loss 3.1348e-01 (3.2392e-01)
Epoch: [11][2350/3491]	Time  5.005 ( 1.579)	Loss 2.9407e-01 (3.2395e-01)
Epoch: [11][2400/3491]	Time  0.483 ( 1.579)	Loss 3.2378e-01 (3.2395e-01)
Epoch: [11][2450/3491]	Time  5.154 ( 1.582)	Loss 3.0233e-01 (3.2395e-01)
Epoch: [11][2500/3491]	Time  0.483 ( 1.583)	Loss 2.9931e-01 (3.2402e-01)
Epoch: [11][2550/3491]	Time  3.868 ( 1.586)	Loss 3.3734e-01 (3.2398e-01)
Epoch: [11][2600/3491]	Time  0.483 ( 1.586)	Loss 3.2182e-01 (3.2390e-01)
Epoch: [11][2650/3491]	Time  7.575 ( 1.589)	Loss 3.2732e-01 (3.2386e-01)
Epoch: [11][2700/3491]	Time  0.483 ( 1.589)	Loss 3.2764e-01 (3.2390e-01)
Epoch: [11][2750/3491]	Time  0.483 ( 1.591)	Loss 3.0726e-01 (3.2394e-01)
Epoch: [11][2800/3491]	Time  0.483 ( 1.593)	Loss 3.0849e-01 (3.2400e-01)
Epoch: [11][2850/3491]	Time  3.976 ( 1.593)	Loss 3.3139e-01 (3.2395e-01)
Epoch: [11][2900/3491]	Time  0.483 ( 1.592)	Loss 3.4419e-01 (3.2391e-01)
Epoch: [11][2950/3491]	Time  8.038 ( 1.595)	Loss 3.2774e-01 (3.2396e-01)
Epoch: [11][3000/3491]	Time  0.483 ( 1.595)	Loss 3.2615e-01 (3.2394e-01)
Epoch: [11][3050/3491]	Time  0.483 ( 1.594)	Loss 3.3086e-01 (3.2395e-01)
Epoch: [11][3100/3491]	Time  0.483 ( 1.593)	Loss 3.2286e-01 (3.2402e-01)
Epoch: [11][3150/3491]	Time  9.374 ( 1.595)	Loss 3.2876e-01 (3.2402e-01)
Epoch: [11][3200/3491]	Time  0.483 ( 1.595)	Loss 3.3195e-01 (3.2399e-01)
Epoch: [11][3250/3491]	Time  0.483 ( 1.596)	Loss 3.0445e-01 (3.2407e-01)
Epoch: [11][3300/3491]	Time  0.483 ( 1.596)	Loss 3.3228e-01 (3.2405e-01)
Epoch: [11][3350/3491]	Time  8.871 ( 1.598)	Loss 3.3634e-01 (3.2406e-01)
Epoch: [11][3400/3491]	Time  0.483 ( 1.597)	Loss 3.2207e-01 (3.2405e-01)
Epoch: [11][3450/3491]	Time  0.484 ( 1.597)	Loss 3.4755e-01 (3.2401e-01)
Val: [0/4]	Time 12.259 (12.259)	Loss 2.8527e-01 (2.8527e-01)
Epoch 0011: val_loss did not improve from 0.33646 
Early Stopping
start testing.....
>> Disease = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']
Creating model...
Creating model from pretrained weights: /home/nyarava/ARK/Ark/ark6_teacher_ep200_swinb_projector1376_mlp.pth.tar
Removing key head.weight from pretrained checkpoint
Removing key head.bias from pretrained checkpoint
Loaded with msg: _IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['projector.0.weight', 'projector.0.bias', 'projector.2.weight', 'projector.2.bias', 'omni_heads.0.weight', 'omni_heads.0.bias', 'omni_heads.1.weight', 'omni_heads.1.bias', 'omni_heads.2.weight', 'omni_heads.2.bias', 'omni_heads.3.weight', 'omni_heads.3.bias', 'omni_heads.4.weight', 'omni_heads.4.bias', 'omni_heads.5.weight', 'omni_heads.5.bias'])
SwinTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): Sequential(
    (0): BasicLayer(
      dim=128, input_resolution=(56, 56), depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=128, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(56, 56), dim=128
        (reduction): Linear(in_features=512, out_features=256, bias=False)
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): BasicLayer(
      dim=256, input_resolution=(28, 28), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(28, 28), dim=256
        (reduction): Linear(in_features=1024, out_features=512, bias=False)
        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): BasicLayer(
      dim=512, input_resolution=(14, 14), depth=18
      (blocks): ModuleList(
        (0-17): 18 x SwinTransformerBlock(
          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=512, out_features=1536, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        input_resolution=(14, 14), dim=512
        (reduction): Linear(in_features=2048, out_features=1024, bias=False)
        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): BasicLayer(
      dim=1024, input_resolution=(7, 7), depth=2
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (head): Linear(in_features=1024, out_features=14, bias=True)
)
=> loaded pre-trained model './Models/Classification/CheXpert/swin_base_ark/swin_base_ark_run_0.pth.tar'
  0%|          | 0/11 [00:00<?, ?it/s]  9%|         | 1/11 [00:15<02:33, 15.32s/it] 18%|        | 2/11 [00:16<01:04,  7.14s/it] 27%|       | 3/11 [00:18<00:36,  4.52s/it] 36%|      | 4/11 [00:19<00:23,  3.29s/it] 45%|     | 5/11 [00:20<00:15,  2.61s/it] 55%|    | 6/11 [00:22<00:10,  2.20s/it] 64%|   | 7/11 [00:23<00:07,  1.94s/it] 73%|  | 8/11 [00:25<00:05,  1.77s/it] 82%| | 9/11 [00:27<00:03,  1.96s/it] 91%| | 10/11 [00:28<00:01,  1.79s/it]100%|| 11/11 [00:30<00:00,  1.85s/it]100%|| 11/11 [00:31<00:00,  2.82s/it]
>>swin_base_ark_run_0: AUC = [0.8892,0.5775,0.896 ,0.9265,0.9149,0.9322,0.873 ,0.8207,0.8762,0.9872,
 0.9642,0.979 ,0.7593,0.9722]
>>swin_base_ark_run_0: AUC = 0.8834
>> All trials: mAUC  = [0.8834]
>> Mean AUC over All trials: = 0.8834
>> STD over All trials:  = 0.0000
